{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f7f60274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'webbrowser' 모듈: 웹 브라우저를 제어하고 URL을 열 수 있게 해줍니다.\n",
    "import webbrowser\n",
    "# 'os' 모듈: 운영체제(Operating System)의 기능에 접근할 수 있게 해줍니다. (이 코드에서는 사용되지 않음)\n",
    "import os\n",
    "# 'requests' 모듈: HTTP 요청(GET, POST 등)을 보내 웹 페이지의 데이터를 가져올 수 있게 해줍니다.\n",
    "import requests\n",
    "# 'bs4'의 'BeautifulSoup' 클래스: HTML이나 XML 파일의 구문 분석(파싱)을 돕고, 데이터를 추출하기 쉽게 만듭니다.\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "39e266b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'www.naver.com'\n",
    "\n",
    "webbrowser.open(url, new=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4ec32aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 네이버 검색 예제 ---\n",
    "\n",
    "# 네이버 검색 기본 URL을 변수에 저장합니다.\n",
    "naver_search_url = 'http://search.naver.com/search.naver?query='\n",
    "# 검색할 단어를 지정합니다. ('파이썬'은 한국어로 'Python'을 의미)\n",
    "search_word = '파이썬'\n",
    "# 기본 URL과 검색어를 결합하여 전체 검색 URL을 완성합니다.\n",
    "url = naver_search_url + search_word\n",
    "# 완성된 URL을 운영체제의 기본 웹 브라우저의 \"새 창\" 또는 \"새 탭\"으로 엽니다.\n",
    "webbrowser.open_new(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "761494cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 구글 검색 예제 (영어) ---\n",
    "\n",
    "# 구글 검색 기본 URL을 변수에 저장합니다.\n",
    "google_url = 'http://www.google.com/search?q='\n",
    "# 검색할 단어를 지정합니다. (여기서는 'python' 영어 단어)\n",
    "search_word = 'python'\n",
    "# 기본 URL과 검색어를 결합하여 전체 검색 URL을 완성합니다.\n",
    "url = google_url + search_word\n",
    "# 완성된 URL을 \"새 창\" 또는 \"새 탭\"으로 엽니다.\n",
    "webbrowser.open_new(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3d28d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 다중 웹사이트 열기 예제 ---\n",
    "\n",
    "# 열고자 하는 여러 웹사이트 URL을 리스트로 정의합니다. (접속 시 'http://'가 자동으로 붙음)\n",
    "urls = ['www.naver.com', 'www.daum.net', 'www.google.com']\n",
    "\n",
    "# 리스트에 있는 각 URL을 반복문(for loop)을 통해 순서대로 처리합니다.\n",
    "for url in urls:\n",
    "    # 각 URL을 \"새 창\" 또는 \"새 탭\"으로 엽니다.\n",
    "    webbrowser.open_new(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "61d842e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 다중 검색어 구글 검색 예제 ---\n",
    "\n",
    "# 구글 검색 기본 URL을 변수에 저장합니다.\n",
    "google_url = \"www.google.com/search?q=\"\n",
    "# 검색할 여러 키워드를 리스트로 정의합니다.\n",
    "search_words = ['python web scraping', 'python webbrowser']\n",
    "# 리스트에 있는 각 검색어를 반복문으로 처리합니다.\n",
    "for search_word in search_words:\n",
    "    # 기본 URL과 검색어를 결합하여 검색을 수행합니다.\n",
    "    # 'webbrowser.open()'은 이미 열려있는 창이 있으면 \"새 탭\"으로 열릴 가능성이 높습니다.\n",
    "    # 'webbrowser.open_new()'와 달리 \"새 창\"을 강제하지 않을 수 있습니다.\n",
    "    webbrowser.open(google_url + search_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8bdc37ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 폴더 생성\n",
    "folder = \"C:/Myexam\"\n",
    "os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a4400ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:/Myexam/HTML_example.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:/Myexam/HTML_example.html\n",
    "<!doctype html>\n",
    "<html>\n",
    "<head>\n",
    " <meta charset=\"utf-8\">\n",
    " <title>이것은 HTML 예제</title>\n",
    "</head>\n",
    "<body>\n",
    " <h1>출간된 책 정보</h1>\n",
    " <p id=\"book_title\">이해가 쏙쏙 되는 파이썬</p>\n",
    " <p id=\"author\">홍길동</p>\n",
    " <p id=\"publisher\">위키북스 출판사</p>\n",
    " <p id=\"year\">2018</p>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a60b1128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:/Myexam/HTML_example2.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:/Myexam/HTML_example2.html\n",
    "<!doctype html>\n",
    "<html>\n",
    "<head>\n",
    " <meta charset=\"utf-8\">\n",
    " <title>이것은 HTML 예제</title>\n",
    " </head>\n",
    "<body>\n",
    " <h1>출간된 책 정보</h1>\n",
    " <p>이해가 쏙쏙 되는 파이썬</p>\n",
    " <p>홍길동</p>\n",
    " <p>위키북스 출판사</p>\n",
    " <p>2018</p>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c41e0a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"ko\"><head><meta content\n"
     ]
    }
   ],
   "source": [
    "# --- 'requests' 모듈을 이용한 웹 페이지 요청 예제 ---\n",
    "\n",
    "# 'requests.get()' 함수를 사용하여 지정된 URL(\"https://www.google.co.kr\")로 \"GET\" 요청을 보냅니다.\n",
    "# (파이썬이 인터넷에서 웹페이지를 가져오라는 요청을 보내는 코드)\n",
    "# 요청의 결과는 'r' 변수(Response 객체)에 저장됩니다.\n",
    "r = requests.get(\"https://www.google.co.kr\")\n",
    "# Response 객체 'r'을 출력합니다.\n",
    "# 보통 \"<Response [200]>\"과 같은 형태로 출력되며, 여기서 '200'은 HTTP 상태 코드로 요청이 \"성공적\"이었음을 나타냅니다.\n",
    "print(r)\n",
    "\n",
    "# Response 객체의 'text' 속성(가져온 웹 페이지의 HTML 소스 코드 문자열)에서\n",
    "# \"처음 100자\"만을 잘라서(슬라이싱) 출력합니다.\n",
    "# 이를 통해 웹 페이지의 \"HTML 소스가 성공적으로 수신\"되었는지 확인할 수 있습니다.\n",
    "print(r.text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ded2edab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html> <body> <div> <span> <a href=\"http://www.naver.com\">naver</a> <a href=\"https://www.google.com\">google</a> <a href=\"http://www.daum.net/\">daum</a> </span> </div> </body> </html> \n"
     ]
    }
   ],
   "source": [
    "# --- 'BeautifulSoup'을 이용한 HTML 파싱(Parsing) 예제 ---\n",
    "\n",
    "# HTML 코드를 포함하는 문자열을 정의합니다.\n",
    "html = \"\"\" <html> <body> <div> <span> <a href=http://www.naver.com>naver</a> <a href=https://www.google.com>google</a> <a href=http://www.daum.net/>daum</a> </span> </div> </body> </html> \"\"\"\n",
    "\n",
    "# BeautifulSoup 객체를 생성합니다.\n",
    "# 첫 번째 인수는 파싱할 HTML 데이터, 두 번째 인수는 사용할 파서(\"lxml\"이 빠르고 강력함)입니다.\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print(soup) # 파싱된 BeautifulSoup 객체 전체를 출력합니다. (입력된 HTML과 거의 같습니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9164994e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <div>\n",
      "   <span>\n",
      "    <a href=\"http://www.naver.com\">\n",
      "     naver\n",
      "    </a>\n",
      "    <a href=\"https://www.google.com\">\n",
      "     google\n",
      "    </a>\n",
      "    <a href=\"http://www.daum.net/\">\n",
      "     daum\n",
      "    </a>\n",
      "   </span>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()) # HTML을 들여쓰기하여 가독성 좋게 출력합니다. (Pretty Print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "24a3742e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'naver'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"soup.find('a')\"는 HTML 문서에서 \"첫 번째\"로 발견되는 \"a\" 태그 요소를 찾습니다.\n",
    "# \".get_text()\"는 해당 태그 안의 텍스트 콘텐츠(\"naver\")만 가져옵니다.\n",
    "soup.find('a').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ba705c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"http://www.naver.com\">naver</a>,\n",
       " <a href=\"https://www.google.com\">google</a>,\n",
       " <a href=\"http://www.daum.net/\">daum</a>]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"soup.find_all('a')\"는 HTML 문서에서 \"모든\" \"a\" 태그 요소를 리스트 형태로 찾습니다.\n",
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cb3a75b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver\n",
      "google\n",
      "daum\n"
     ]
    }
   ],
   "source": [
    "# 찾은 모든 \"a\" 태그 요소를 \"site_names\" 변수에 저장합니다.\n",
    "site_names = soup.find_all('a')\n",
    "# 리스트의 각 태그에 대해 반복합니다.\n",
    "for site_name in site_names:\n",
    "    print(site_name.get_text()) # 각 태그의 텍스트 콘텐츠(\"naver\", \"google\", \"daum\")를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e871b073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html> <head> <title>작품과 작가 모음</title> </head> <body> <h1>책 정보</h1> <p id=\"book_title\">토지</p> <p id=\"author\">박경리</p> <p id=\"book_title\">태백산맥</p> <p id=\"author\">조정래</p> <p id=\"book_title\">감옥으로부터의 사색</p><p id=\"author\">신영복</p> </body></html>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- ID 속성으로 요소 찾기 (Finding Elements by ID Attribute) ---\n",
    "\n",
    "\n",
    "# 새로운 HTML 코드를 정의합니다. 여러 개의 같은 태그(\"p\")에 다른 \"id\" 속성이 할당되어 있습니다.\n",
    "html2 = \"\"\"<html> <head>  <title>작품과 작가 모음</title> </head> <body>  <h1>책 정보</h1>  <p id=\"book_title\">토지</p>  <p id=\"author\">박경리</p>    <p id=\"book_title\">태백산맥</p>  <p id=\"author\">조정래</p>  <p id=\"book_title\">감옥으로부터의 사색</p><p id=\"author\">신영복</p> </body></html>\"\"\"\n",
    "\n",
    "soup2 = BeautifulSoup(html2, \"lxml\") # BeautifulSoup 객체를 생성합니다.\n",
    "\n",
    "soup2 # 객체 자체를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "066f3cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   작품과 작가 모음\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   책 정보\n",
      "  </h1>\n",
      "  <p id=\"book_title\">\n",
      "   토지\n",
      "  </p>\n",
      "  <p id=\"author\">\n",
      "   박경리\n",
      "  </p>\n",
      "  <p id=\"book_title\">\n",
      "   태백산맥\n",
      "  </p>\n",
      "  <p id=\"author\">\n",
      "   조정래\n",
      "  </p>\n",
      "  <p id=\"book_title\">\n",
      "   감옥으로부터의 사색\n",
      "  </p>\n",
      "  <p id=\"author\">\n",
      "   신영복\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup2.prettify()) # 보기 좋게 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "09573f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>작품과 작가 모음</title>\n"
     ]
    }
   ],
   "source": [
    "print(soup2.title) # HTML 문서의 \"<title>\" 태그 전체를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "654ad0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body> <h1>책 정보</h1> <p id=\"book_title\">토지</p> <p id=\"author\">박경리</p> <p id=\"book_title\">태백산맥</p> <p id=\"author\">조정래</p> <p id=\"book_title\">감옥으로부터의 사색</p><p id=\"author\">신영복</p> </body>\n"
     ]
    }
   ],
   "source": [
    "print(soup2.body) # HTML 문서의 \"<body>\" 태그 전체를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7f1e37d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>책 정보</h1>\n"
     ]
    }
   ],
   "source": [
    "print(soup2.body.h1) # \"body\" 태그 안의 \"h1\" 태그 전체를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3465ae39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"book_title\">토지</p>, <p id=\"author\">박경리</p>, <p id=\"book_title\">태백산맥</p>, <p id=\"author\">조정래</p>, <p id=\"book_title\">감옥으로부터의 사색</p>, <p id=\"author\">신영복</p>]\n"
     ]
    }
   ],
   "source": [
    "# 태그 이름이 \"p\"인 모든 요소를 리스트로 찾습니다.\n",
    "print(soup2.find_all('p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "260e450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"book_title\">토지</p>\n"
     ]
    }
   ],
   "source": [
    "# \"p\" 태그 중 \"id\" 속성이 \"book_title\"인 \"첫 번째\" 요소를 찾습니다.\n",
    "print(soup2.find('p', {\"id\":\"book_title\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "85f8eb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"author\">박경리</p>\n"
     ]
    }
   ],
   "source": [
    "# \"p\" 태그 중 \"id\" 속성이 \"author\"인 \"첫 번째\" 요소를 찾습니다.\n",
    "print(soup2.find('p', {\"id\":\"author\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "77f513c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"book_title\">토지</p>, <p id=\"book_title\">태백산맥</p>, <p id=\"book_title\">감옥으로부터의 사색</p>]\n"
     ]
    }
   ],
   "source": [
    "# \"p\" 태그 중 \"id\" 속성이 \"book_title\"인 \"모든\" 요소를 리스트로 찾습니다.\n",
    "print(soup2.find_all('p', {\"id\":\"book_title\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "149a7f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"author\">박경리</p>, <p id=\"author\">조정래</p>, <p id=\"author\">신영복</p>]\n"
     ]
    }
   ],
   "source": [
    "# \"p\" 태그 중 \"id\" 속성이 \"author\"인 \"모든\" 요소를 리스트로 찾습니다.\n",
    "print(soup2.find_all('p', {\"id\":\"author\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2ad61889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토지/박경리\n",
      "태백산맥/조정래\n",
      "감옥으로부터의 사색/신영복\n"
     ]
    }
   ],
   "source": [
    "# --- zip을 이용한 데이터 매칭 및 추출 (Data Matching and Extraction using zip) ---\n",
    "\n",
    "\n",
    "soup2 = BeautifulSoup(html2, \"lxml\")\n",
    "# 모든 책 제목 요소를 찾습니다.\n",
    "book_titles = soup2.find_all('p', {\"id\":\"book_title\"})\n",
    "# 모든 작가 이름 요소를 찾습니다.\n",
    "authors = soup2.find_all('p', {\"id\":\"author\"})\n",
    "\n",
    "# \"zip\" 함수를 사용하여 책 제목 리스트와 작가 이름 리스트의 요소를 순서대로 묶어 반복합니다.\n",
    "for book_title, author in zip(book_titles, authors):\n",
    "    # 각 요소에서 텍스트만 추출하여 \"책제목/작가이름\" 형태로 출력합니다.\n",
    "    print(book_title.get_text() + '/' + author.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7d0a0855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1>책 정보</h1>]\n"
     ]
    }
   ],
   "source": [
    "# --- CSS 선택자 (select) 사용 (Using CSS Selectors) ---\n",
    "\n",
    "\n",
    "# CSS 선택자(\"select\")를 사용하여 \"body\" 태그 아래의 \"h1\" 태그를 모두 찾습니다.\n",
    "print(soup2.select('body h1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "241b52b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"book_title\">토지</p>, <p id=\"author\">박경리</p>, <p id=\"book_title\">태백산맥</p>, <p id=\"author\">조정래</p>, <p id=\"book_title\">감옥으로부터의 사색</p>, <p id=\"author\">신영복</p>]\n"
     ]
    }
   ],
   "source": [
    "# CSS 선택자를 사용하여 \"body\" 태그 아래의 \"p\" 태그를 모두 찾습니다. (공백은 하위 요소를 의미)\n",
    "print(soup2.select('body p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "543cb54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"book_title\">토지</p>, <p id=\"author\">박경리</p>, <p id=\"book_title\">태백산맥</p>, <p id=\"author\">조정래</p>, <p id=\"book_title\">감옥으로부터의 사색</p>, <p id=\"author\">신영복</p>]\n"
     ]
    }
   ],
   "source": [
    "# 문서 내의 모든 \"p\" 태그를 찾습니다.\n",
    "print(soup2.select('p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d1d1a1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"book_title\">토지</p>, <p id=\"book_title\">태백산맥</p>, <p id=\"book_title\">감옥으로부터의 사색</p>]\n"
     ]
    }
   ],
   "source": [
    "# \"p\" 태그 중에서 \"id\"가 \"book_title\"인 요소를 찾습니다. (\"#\"은 ID를 나타냄)\n",
    "print(soup2.select('p#book_title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "322ce849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"author\">박경리</p>, <p id=\"author\">조정래</p>, <p id=\"author\">신영복</p>]\n"
     ]
    }
   ],
   "source": [
    "# \"p\" 태그 중에서 \"id\"가 \"author\"인 요소를 찾습니다.\n",
    "print(soup2.select('p#author'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "04d29b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 파일에서 HTML 읽기 및 클래스/ID 선택자 사용 (Reading HTML from File and Class/ID Selectors) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "45f07dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:/Myexam/HTML_example_my_site.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:/Myexam/HTML_example_my_site.html\n",
    "<!doctype html>\n",
    "<html>\n",
    " <head>\n",
    " <meta charset=\"utf-8\">\n",
    " <title>사이트 모음</title>\n",
    " </head>\n",
    " <body>\n",
    " <p id=\"title\"><b>자주 가는 사이트 모음</b></p>\n",
    " <p id=\"contents\">이곳은 자주 가는 사이트를 모아둔 곳입니다.</p>\n",
    " <a href=\"http://www.naver.com\" class=\"portal\" id=\"naver\">네이버</a> <br>\n",
    " <a href=\"https://www.google.com\" class=\"search\" id=\"google\">구글</a> <br>\n",
    " <a href=\"http://www.daum.net\" class=\"portal\" id=\"daum\">다음</a> <br>\n",
    " <a href=\"http://www.nl.go.kr\" class=\"government\" id=\"nl\">국립중앙도서관</a>\n",
    " </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5bb4720e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"portal\" href=\"http://www.naver.com\" id=\"naver\">네이버</a>, <a class=\"search\" href=\"https://www.google.com\" id=\"google\">구글</a>, <a class=\"portal\" href=\"http://www.daum.net\" id=\"daum\">다음</a>, <a class=\"government\" href=\"http://www.nl.go.kr\" id=\"nl\">국립중앙도서관</a>]\n"
     ]
    }
   ],
   "source": [
    "# 'C:/Myexam/HTML_example_my_site.html' 파일을 UTF-8 인코딩으로 열어 \"f\"에 할당합니다.\n",
    "f = open('C:/Myexam/HTML_example_my_site.html', encoding='utf-8')\n",
    "html3 = f.read() # 파일의 내용을 모두 읽어 \"html3\"에 저장합니다.\n",
    "f.close() # 파일을 닫습니다.\n",
    "soup3 = BeautifulSoup(html3, \"lxml\") # BeautifulSoup 객체를 생성합니다.\n",
    "\n",
    "\n",
    "print(soup3.select('a')) # 문서 내의 모든 \"a\" 태그를 찾습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e0407568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"portal\" href=\"http://www.naver.com\" id=\"naver\">네이버</a>, <a class=\"portal\" href=\"http://www.daum.net\" id=\"daum\">다음</a>]\n"
     ]
    }
   ],
   "source": [
    "# \"a\" 태그 중에서 \"class\" 속성이 \"portal\"인 요소를 찾습니다. (\".\"은 클래스를 나타냄)\n",
    "print(soup3.select('a.portal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dce9fe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"portal\" href=\"http://www.naver.com\" id=\"naver\">네이버</a>]\n"
     ]
    }
   ],
   "source": [
    "# \"a\" 태그 중에서 \"id\" 속성이 \"naver\"인 요소를 찾습니다. (\"#\"은 ID를 나타냄)\n",
    "print(soup3.select('a#naver'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "67ba33d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:/Myexam/br_example_constitution.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:/Myexam/br_example_constitution.html\n",
    "<!doctype html>\n",
    "<html>\n",
    " <head>\n",
    " <meta charset=\"utf-8\">\n",
    " <title>줄 바꿈 테스트 예제</title>\n",
    " </head>\n",
    " <body>\n",
    " <p id=\"title\"><b>대한민국헌법</b></p>\n",
    " <p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.<\n",
    " <p id=\"content\">제2조 <br/>①대한민국의 국민이 되는 요건은 법률로 정한다.<br/>②국가는 법률이 정하는 바에 의하여 재외국민을 보호\n",
    " </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "98f08e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<title>줄 바꿈 테스트 예제</title>\n",
       "</head>\n",
       "<body>\n",
       "<p id=\"title\"><b>대한민국헌법</b></p>\n",
       "<p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.&lt;\n",
       " </p><p id=\"content\">제2조 <br/>①대한민국의 국민이 되는 요건은 법률로 정한다.<br/>②국가는 법률이 정하는 바에 의하여 재외국민을 보호\n",
       " </p></body>\n",
       "</html>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 텍스트 추출 및 <br/> 태그 처리 - 1 (Text Extraction and $<br/>$ Handling - Part 1) ---\n",
    "\n",
    "\n",
    "# 'C:/Myexam/br_example_constitution.html' 파일을 읽어옵니다.\n",
    "f = open('C:/Myexam/br_example_constitution.html', encoding='utf-8')\n",
    "html_source = f.read()\n",
    "f.close()\n",
    "soup = BeautifulSoup(html_source, \"lxml\")\n",
    "\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f992a262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"title\"><b>대한민국헌법</b></p>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"id\"가 \"title\"인 \"p\" 태그를 찾습니다.\n",
    "title = soup.find('p', {\"id\":\"title\"})\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c9dc192e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.&lt;\n",
       "  </p>,\n",
       " <p id=\"content\">제2조 <br/>①대한민국의 국민이 되는 요건은 법률로 정한다.<br/>②국가는 법률이 정하는 바에 의하여 재외국민을 보호\n",
       "  </p>]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"id\"가 \"content\"인 \"p\" 태그를 \"모두\" 찾습니다.\n",
    "contents = soup.find_all('p', {\"id\":\"content\"})\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "cbf8c05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국헌법\n"
     ]
    }
   ],
   "source": [
    "print(title.get_text()) # 제목의 텍스트를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "45046a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제1조 ①대한민국은 민주공화국이다.②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.<\n",
      " \n",
      "제2조 ①대한민국의 국민이 되는 요건은 법률로 정한다.②국가는 법률이 정하는 바에 의하여 재외국민을 보호\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# 내용 리스트를 반복하며 각 내용의 텍스트를 출력합니다.\n",
    "for content in contents:\n",
    "    print(content.get_text())\n",
    "\n",
    "# 핵심 기능: 파일에서 데이터를 읽고, **find**와 **find_all**을 사용하여 제목과 내용을 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "520e6e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p></body></html>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html1 = '<p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>'\n",
    "soup1 = BeautifulSoup(html1, \"lxml\")\n",
    "soup1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3fe6cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 태그 p로 찾은 요소\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"==> 태그 p로 찾은 요소\")\n",
    "content1 = soup1.find('p', {\"id\":\"content\"})\n",
    "content1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4469108e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<br/>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 찾은 \"content1\" 태그 안에서 \"첫 번째\" \"<br/>\" 태그를 찾습니다.\n",
    "br_content = content1.find(\"br\")\n",
    "br_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "dddfda45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<br/>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 찾은 \"<br/>\" 태그를 Python의 개행 문자(\"\\n\")로 대체합니다.\n",
    "br_content.replace_with(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "173ca5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"content\">제1조 \n",
       "①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변경된 \"content1\" 태그를 출력합니다. (첫 번째 \"<br/>\"만 변경됨)\n",
    "content1\n",
    "\n",
    "# 핵심 기능: replace_with(\"\\n\") 메서드를 사용하여 HTML의 줄 바꿈 태그인 **<br/>**을\n",
    "# 텍스트 줄 바꿈(\\n) 문자로 바꾸는 방법을 보여줍니다.\n",
    "# 다만, 이 예시에서는 \"첫 번째\" <br/>만 처리됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "dba1b5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- <br/> 태그 전체 처리 (Handling All $<br/>$ Tags) ---\n",
    "\n",
    "\n",
    "soup2 = BeautifulSoup(html1, \"lxml\")\n",
    "content2 = soup2.find('p', {\"id\":\"content\"})\n",
    "content2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1657dd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<br/>, <br/>]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"content2\" 태그 안에서 \"모든\" \"<br/>\" 태그를 리스트로 찾습니다.\n",
    "br_contents = content2.find_all(\"br\")\n",
    "br_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c106f386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"content\">제1조 \n",
       "①대한민국은 민주공화국이다.\n",
       "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 찾은 모든 \"<br/>\" 태그에 대해 반복합니다.\n",
    "for br_content in br_contents:\n",
    "    br_content.replace_with(\"\\n\") # 각 \"<br/>\" 태그를 개행 문자(\"\\n\")로 대체합니다.\n",
    "\n",
    "# 모든 \"<br/>\"이 \"\\n\"으로 대체된 최종 결과를 출력합니다.\n",
    "content2\n",
    "\n",
    "# 핵심 기능: **find_all(\"br\")**로 모든 <br/> 태그를 찾은 후, \n",
    "# for 루프를 돌면서 각각 **replace_with(\"\\n\")**를 적용하여 \n",
    "# HTML 내용 안의 모든 줄 바꿈을 텍스트 형식으로 변경합니다. \n",
    "# 이는 텍스트 데이터를 깔끔하게 정리하는 데 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6f9d8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- replace_newline 함수 ---\n",
    "\n",
    "\n",
    "def replace_newline(soup_html):\n",
    "    # 함수 정의: HTML 파싱 객체(BeautifulSoup 객체)를 인수로 받습니다.\n",
    "    # 인수로 받는 변수 이름은 \"soup_html\"이며, 함수 실행 후 변환된 객체를 반환합니다.\n",
    "\n",
    "    # 1. 모든 <br> 태그 찾기\n",
    "    # \"soup_html\" 객체에서 \"find_all()\" 메서드를 사용하여 HTML 문서 내의 모든 \"<br>\" 태그 요소를 찾습니다.\n",
    "    # 찾은 모든 요소들은 리스트 형태로 \"br_to_newlines\" 변수에 저장됩니다.\n",
    "    br_to_newlines = soup_html.find_all(\"br\")\n",
    "\n",
    "    # 2. 반복문을 사용한 태그 변환\n",
    "    # \"br_to_newlines\" 리스트의 각 요소(각 \"<br>\" 태그)에 대해 반복합니다.\n",
    "    for br_to_newline in br_to_newlines:\n",
    "        # \".replace_with('\\n')\" 메서드를 사용합니다.\n",
    "        # 현재 반복 중인 \"<br>\" 태그를 Python의 개행 문자(\"\\n\")로 \"대체\"합니다.\n",
    "        # 이 작업은 원본 \"soup_html\" 객체에 직접 반영됩니다.\n",
    "        br_to_newline.replace_with(\"\\n\")\n",
    "\n",
    "    # 3. 변환된 객체 반환\n",
    "    # 모든 `<br/>` 태그가 `\\n`으로 대체되어 텍스트가 정리된 \"soup_html\" 객체를 반환합니다.\n",
    "    return soup_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ab5b0c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p></body></html>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- replace_newline 함수 적용 코드 ---\n",
    "\n",
    "# 'html1' 변수에 저장된 HTML 문자열을 사용하여 새로운 BeautifulSoup 객체 \"soup2\"를 생성합니다.\n",
    "# 이 객체는 이전 `<br/>` 처리의 영향을 받지 않은 초기 상태입니다.\n",
    "# html1 = '<p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나</p>'\n",
    "soup2 = BeautifulSoup(html1, \"lxml\")\n",
    "soup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6b09bc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"soup2\" 객체에서 \"id\" 속성이 \"content\"인 \"p\" 태그 요소를 찾습니다.\n",
    "# 이 요소는 \"<br/>\" 태그들을 포함하고 있습니다.\n",
    "content2 = soup2.find('p', {\"id\":\"content\"})\n",
    "content2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9a1529d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"content\">제1조 \n",
       "①대한민국은 민주공화국이다.\n",
       "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 앞서 정의된 \"replace_newline\" 함수를 호출하여 \"content2\" 요소 내의 작업을 수행합니다.\n",
    "# 1. 함수는 \"content2\" 객체 안의 모든 \"<br/>\" 태그를 찾습니다.\n",
    "# 2. 각 \"<br/>\" 태그를 개행 문자(\"\\n\")로 대체합니다.\n",
    "# 3. 변경된 객체를 반환하며, 이 결과가 \"content3\"에 저장됩니다. (content2와 content3는 같은 객체를 참조)\n",
    "content3 = replace_newline(content2)\n",
    "content3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d6d11133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제1조 \n",
      "①대한민국은 민주공화국이다.\n",
      "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.\n"
     ]
    }
   ],
   "source": [
    "# 최종적으로, 변환 작업이 완료된 \"content3\" 객체에서 순수한 \"텍스트 내용\"만을 추출하여 출력합니다.\n",
    "# get_text() 결과에는 \"<br/>\" 대신 삽입된 \"\\n\" 문자열이 반영되어 줄 바꿈이 적용됩니다.\n",
    "print(content3.get_text())\n",
    "\n",
    "# 이 과정은 웹 스크래핑에서 **\"HTML 줄 바꿈과 텍스트 줄 바꿈을 일치\"**시키는 매우 실용적인 기술을 보여줍니다. \n",
    "# content2에서 get_text()를 바로 호출하면 모든 텍스트가 한 줄로 이어지지만, \n",
    "# replace_newline 함수를 적용함으로써 원본 HTML의 의도된 줄 바꿈을 텍스트 데이터에 그대로 반영할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6db145bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"title\"><b>대한민국헌법</b></p>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 파일 읽기 및 <br/> 처리 ---\n",
    "\n",
    "# 'html_source' 변수에 저장된 HTML 전체 내용을 사용하여 BeautifulSoup 객체 \"soup\"를 새로 생성합니다.\n",
    "# 이 HTML은 아마도 'C:/Myexam/br_example_constitution.html' 파일에서 읽어온 내용일 것입니다.\n",
    "soup = BeautifulSoup(html_source, \"lxml\")\n",
    "\n",
    "# 1. 제목(Title) 추출\n",
    "# \"id\" 속성이 \"title\"인 \"p\" 태그 요소를 문서 전체에서 \"첫 번째\"로 찾아 \"title\" 변수에 저장합니다.\n",
    "title = soup.find('p', {\"id\":\"title\"})\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ab1be5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.&lt;\n",
       "  </p>,\n",
       " <p id=\"content\">제2조 <br/>①대한민국의 국민이 되는 요건은 법률로 정한다.<br/>②국가는 법률이 정하는 바에 의하여 재외국민을 보호\n",
       "  </p>]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 내용(Contents) 추출\n",
    "# \"id\" 속성이 \"content\"인 \"p\" 태그 요소를 문서 전체에서 \"모두\" 찾아 리스트 형태로 \"contents\" 변수에 저장합니다.\n",
    "contents = soup.find_all('p', {\"id\":\"content\"})\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "21794664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국헌법 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. 제목 출력\n",
    "# 찾은 제목 요소에서 순수한 텍스트만 추출하여 출력합니다.\n",
    "# 출력 후, 다음 내용과의 구분을 위해 두 줄(\\n)을 띄웁니다. (title.get_text() + '\\n')\n",
    "print(title.get_text(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "14e16b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제1조 \n",
      "①대한민국은 민주공화국이다.\n",
      "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.<\n",
      "  \n",
      "\n",
      "제2조 \n",
      "①대한민국의 국민이 되는 요건은 법률로 정한다.\n",
      "②국가는 법률이 정하는 바에 의하여 재외국민을 보호\n",
      "  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. 내용 반복 처리 및 출력\n",
    "# 내용 리스트(\"contents\")의 각 요소(예: 각 조항의 내용)에 대해 반복합니다.\n",
    "for content in contents:\n",
    "    # 현재 내용 요소(\"content\")를 앞서 정의된 \"replace_newline\" 함수에 전달합니다.\n",
    "    # 함수 내에서 해당 요소의 모든 \"<br/>\" 태그가 \"\\n\"으로 대체되어 텍스트가 정리됩니다.\n",
    "    # 변환된 결과(content1)는 원본 객체와 동일하며, 정리된 HTML 조각을 담고 있습니다.\n",
    "    content1 = replace_newline(content)\n",
    "\n",
    "    # 정리된 HTML 조각(\"content1\")에서 순수한 텍스트를 추출하여 출력합니다.\n",
    "    # 출력 후, 다음 조항과의 구분을 위해 한 줄(\\n)을 띄웁니다.\n",
    "    print(content1.get_text(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "94f7a218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# --- 이미지 파일 다운로드 ---\n",
    "    \n",
    "# 1. 이미지 URL 정의\n",
    "# 다운로드하려는 이미지 파일의 전체 URL을 문자열로 'url' 변수에 저장합니다.\n",
    "# 이 URL은 Python 공식 웹사이트의 로고 이미지(.png 파일)를 가리킵니다.\n",
    "url = 'https://www.python.org/static/img/python-logo.png'\n",
    "\n",
    "# 2. HTTP GET 요청 전송 및 응답 객체 저장\n",
    "# 'requests.get(url)' 함수를 사용하여 해당 URL로 HTTP GET 요청을 보냅니다.\n",
    "# 웹 서버는 이 요청에 대한 응답으로 이미지 파일의 바이너리 데이터를 포함하는 \"Response 객체\"를 반환합니다.\n",
    "# 이 객체는 'html_image' 변수에 저장됩니다.\n",
    "html_image = requests.get(url)\n",
    "\n",
    "# 3. 응답 객체 출력\n",
    "# Response 객체('html_image') 자체를 출력합니다.\n",
    "# 이 코드는 서버로부터 요청이 성공했는지 여부를 즉시 확인하는 데 사용됩니다.\n",
    "print(html_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "cc22dd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python-logo.png\n"
     ]
    }
   ],
   "source": [
    "# --- 파일 이름 추출 --- \n",
    "\n",
    "# 1. 파일 이름 추출\n",
    "# 'os.path.basename(url)' 함수를 호출합니다.\n",
    "# 이 함수는 파일 경로나 URL에서 파일 이름만을 추출하는 함수입니다.\n",
    "# 주로 경로에서 마지막 부분(파일명이나 마지막 폴더명)을 얻을 때 사용됩니다.\n",
    "# URL의 경로 구분자('/') 이후의 모든 문자열('python-logo.png')이 추출되어 'image_file_name' 변수에 저장됩니다.\n",
    "image_file_name = os.path.basename(url)\n",
    "print(image_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f48aa336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 폴더 생성 및 파일 경로 구성 ---\n",
    "\n",
    "\n",
    "\n",
    "# 1. 폴더 생성 및 확인 (Directory Creation and Check)\n",
    "\n",
    "# 이미지 파일을 저장할 목표 폴더 경로를 'folder' 변수에 문자열로 정의합니다.\n",
    "folder = 'C:/Myexam/download' \n",
    "\n",
    "# 'os.path.exists(folder)' 함수를 사용하여 정의된 'folder' 경로가 운영체제에 **\"실제로 존재하는지\"** 확인합니다.\n",
    "if not os.path.exists(folder):\n",
    "    # 만약 폴더가 존재하지 않는다면 (if not True, 즉 False라면):\n",
    "    \n",
    "    # 'os.makedirs(folder)' 함수를 사용하여 해당 경로의 폴더를 생성합니다.\n",
    "    # 이 함수는 중간 경로('C:/Myexam')도 함께 생성해줍니다. (mkdir()과는 다름)\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6be22758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Myexam/download\\python-logo.png\n"
     ]
    }
   ],
   "source": [
    "# 2. 최종 이미지 경로 구성 (Final Image Path Construction)\n",
    "\n",
    "# 'os.path.join(folder, image_file_name)' 함수를 사용하여 디렉터리 경로와 파일 이름을 결합합니다.\n",
    "# 이 함수는 운영체제(Windows, Linux, macOS)에 맞는 **\"올바른 경로 구분자\"**를 자동으로 사용하여 최종 파일 경로를 생성합니다.\n",
    "# 예: 'C:/Myexam/download' + '/' + 'python-logo.png' -> 'C:/Myexam/download/python-logo.png'\n",
    "image_path = os.path.join(folder, image_file_name)\n",
    "\n",
    "# 'image_path' 변수에 저장된 최종 경로를 출력합니다. (Jupyter/Colab 환경에서는 변수만 적으면 출력됨)\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "fdcd38ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 이미지 파일 저장 및 확인 ---\n",
    "\n",
    "# 1. 이미지 파일 저장 (Writing the Image File)\n",
    "\n",
    "# 'image_path' 변수(예: 'C:/Myexam/download/python-logo.png')에 지정된 경로로 파일을 엽니다.\n",
    "# 'wb' 모드(write binary)는 이미지와 같은 바이너리 데이터를 \"쓰기\" 위해 사용됩니다.\n",
    "# 파일 객체는 'imageFile' 변수에 저장됩니다.\n",
    "imageFile = open(image_path, 'wb')\n",
    "\n",
    "# 파일 저장 시 사용할 청크(조각) 크기를 바이트 단위로 정의합니다.\n",
    "# \"chunk_size\" = 1,000,000 바이트 (약 1MB)로 설정되어 있습니다.\n",
    "chunk_size = 1000000\n",
    "\n",
    "# \"html_image\" Response 객체에서 \".iter_content(chunk_size)\" 메서드를 사용하여 데이터를 반복합니다.\n",
    "# 이 메서드는 이미지 데이터를 설정된 \"chunk_size\" 단위로 나누어 반환합니다.\n",
    "# 큰 파일을 처리할 때 메모리 부하를 줄이는 데 매우 효율적입니다.\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    # 반복문에서 얻은 데이터 조각(\"chunk\")을 'imageFile' 객체를 통해 디스크에 \"쓰기\"를 수행합니다.\n",
    "    imageFile.write(chunk)\n",
    "\n",
    "# 모든 데이터 조각이 쓰여지면, 파일에 대한 작업을 완료하고 'imageFile' 객체를 \"닫습니다\".\n",
    "# 파일을 닫는 것은 데이터의 손실을 막고 시스템 자원을 해제하는 데 중요합니다.\n",
    "imageFile.close()\n",
    "\n",
    "\n",
    "# \"핵심 기능\": iter_content()를 사용하여 스트리밍 방식으로 데이터를 읽고 **write()**로 디스크에 저장함으로써,\n",
    "# 메모리에 전체 파일을 한 번에 로드하지 않고도 큰 파일을 안정적으로 다운로드할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "deda282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['external-link-arrow-9fdf3fbf53535dc5eb554a9a5d5601329bb7bb7169ee72746a37fac0527b2967.svg', 'python-logo.png']\n"
     ]
    }
   ],
   "source": [
    "# 2. 저장 확인 (Verification)\n",
    "\n",
    "# 'os.listdir(folder)' 함수를 사용하여 'folder' 변수(예: 'C:/Myexam/download')가 가리키는\n",
    "# 디렉터리 내의 모든 파일과 폴더 \"이름\"을 리스트 형태로 가져옵니다.\n",
    "print(os.listdir(folder))\n",
    "\n",
    "# 이 출력 결과에 'python-logo.png'와 같은 \"image_file_name\"이 포함되어 있다면 파일 저장이 성공했음을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b7e56a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python-logo.png'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 웹 이미지 다운로드 전체 ---\n",
    "\n",
    "\n",
    "# --- 1. \"초기 설정 및 요청\" (Setup and Request) ---\n",
    "\n",
    "\n",
    "# 다운로드할 이미지 파일의 전체 URL을 'url' 변수에 저장합니다.\n",
    "url = 'https://www.python.org/static/img/python-logo.png'\n",
    "\n",
    "# \"requests.get()\" 함수를 사용하여 해당 URL로 HTTP GET 요청을 보냅니다.\n",
    "# 웹 서버로부터 이미지 파일의 바이너리 데이터를 포함하는 \"Response 객체\"를 'html_image'에 저장합니다.\n",
    "html_image = requests.get(url)\n",
    "\n",
    "# \"os.path.basename(url)\" 함수를 사용하여 URL 경로에서 \"순수한 파일 이름\"('python-logo.png')만을 추출하여 'image_file_name'에 저장합니다.\n",
    "image_file_name = os.path.basename(url)\n",
    "image_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f21758ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. \"저장 폴더 확인 및 생성\" (Folder Check and Creation) ---\n",
    "\n",
    "\n",
    "# 이미지 파일을 저장할 로컬 목표 폴더 경로를 'folder' 변수에 정의합니다.\n",
    "folder = 'C:/Myexam/download' \n",
    "\n",
    "# \"os.path.exists(folder)\" 함수를 사용하여 해당 경로에 폴더가 \"존재하는지\" 확인합니다.\n",
    "if not os.path.exists(folder):\n",
    "    # 폴더가 존재하지 않는다면:\n",
    "    \n",
    "    # \"os.makedirs(folder)\" 함수를 사용하여 해당 폴더를 \"생성\"합니다.\n",
    "    # 중간 디렉터리(예: 'C:/Myexam')도 존재하지 않으면 함께 생성됩니다.\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# \"os.path.join(folder, image_file_name)\" 함수를 사용하여 폴더 경로와 파일 이름을 결합하여 \n",
    "# \"파일이 저장될 최종 경로\"('C:/Myexam/download/python-logo.png')를 'image_path'에 구성합니다.\n",
    "image_path = os.path.join(folder, image_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "69f03a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. \"파일 스트리밍 저장\" (Streaming File Save) ---\n",
    "\n",
    "\n",
    "# \"image_path\"에 지정된 경로로 파일을 \"열고\" 파일 객체를 'imageFile'에 저장합니다.\n",
    "# 'wb' 모드(write binary)는 텍스트가 아닌 \"바이너리\" 데이터(이미지)를 쓰기 위해 \"필수적\"입니다.\n",
    "imageFile = open(image_path, 'wb')\n",
    "\n",
    "# 파일 저장 시 메모리 효율을 높이기 위해 데이터를 나눌 \"청크 크기\"를 바이트 단위로 정의합니다.\n",
    "# \"chunk_size\" = 1,000,000 바이트 (약 1MB)입니다.\n",
    "chunk_size = 1000000\n",
    "\n",
    "# \"html_image.iter_content(chunk_size)\" 메서드를 사용하여 Response 객체의 이미지 데이터를 \n",
    "# \"chunk_size\" 단위로 나누어 \"반복적\"으로 읽어옵니다. (스트리밍)\n",
    "# 이 방법은 파일 전체를 메모리에 한 번에 올리지 않아 \"대용량 파일\" 다운로드에 유리합니다.\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    # 반복을 통해 얻은 데이터 조각(\"chunk\")을 'imageFile' 객체를 통해 디스크에 \"쓰기\"를 수행합니다.\n",
    "    imageFile.write(chunk)\n",
    "\n",
    "# 모든 데이터 쓰기 작업이 완료되면, \"imageFile.close()\"를 호출하여 파일을 \"닫고\" 시스템 자원을 해제합니다.\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ba945ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img alt=\"Reshot\" height=\"33\" src=\"https://www.reshot.com/build/reshot-logo--mark-f8dfafbc1cc8fbf4dfa0e2f210265735aefa6e32f883b5a1fe27fd94f84719b3.svg\" title=\"Reshot\" width=\"46\"/>,\n",
       " <img alt=\"External link\" height=\"16\" loading=\"lazy\" src=\"https://www.reshot.com/build/photos/external-link-arrow-9fdf3fbf53535dc5eb554a9a5d5601329bb7bb7169ee72746a37fac0527b2967.svg\" width=\"16\"/>,\n",
       " <img alt=\"External link\" height=\"16\" loading=\"lazy\" src=\"https://www.reshot.com/build/photos/external-link-arrow-9fdf3fbf53535dc5eb554a9a5d5601329bb7bb7169ee72746a37fac0527b2967.svg\" width=\"16\"/>,\n",
       " <img alt=\"Reshot\" class=\"global-footer__logo-image\" height=\"82\" src=\"https://www.reshot.com/build/reshot-logo--mark-f8dfafbc1cc8fbf4dfa0e2f210265735aefa6e32f883b5a1fe27fd94f84719b3.svg\" title=\"Reshot\" width=\"113\"/>]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 웹 이미지 스크래핑 및 다운로드 ---\n",
    "\n",
    "\n",
    "# 1. \"웹페이지 데이터 가져오기 및 파싱\" (Fetch and Parse Webpage Data)\n",
    "\n",
    "# 이미지 소스를 찾을 웹페이지 URL을 'URL' 변수에 저장합니다. (무료 스톡 이미지 사이트)\n",
    "URL = 'https://reshot.com/search/animal'\n",
    "\n",
    "# \"requests.get(URL)\"을 사용하여 해당 URL로 HTTP GET 요청을 보내고, \n",
    "# \".text\" 속성을 이용해 응답으로 받은 HTML 소스 코드를 문자열로 추출하여 'html_reshot_image'에 저장합니다.\n",
    "html_reshot_image = requests.get(URL).text\n",
    "\n",
    "# BeautifulSoup 객체를 생성합니다.\n",
    "# 첫 번째 인수로 HTML 소스 코드 문자열을, 두 번째 인수로 \"lxml\" 파서를 지정하여 HTML 구조를 분석합니다.\n",
    "soup_reshot_image = BeautifulSoup(html_reshot_image, \"lxml\")\n",
    "\n",
    "# CSS 선택자(\"a img\")를 사용하여 특정 이미지 요소를 찾습니다.\n",
    "# 이는 <a> 태그 안에 있는 모든 <img> 태그를 의미하며, 일반적으로 클릭 가능한 이미지 링크를 찾을 때 사용됩니다.\n",
    "# 찾은 모든 요소는 리스트 형태로 'reshot_image_elements'에 저장됩니다.\n",
    "reshot_image_elements = soup_reshot_image.select('a img') \n",
    "\n",
    "# 찾은 이미지 요소 리스트의 앞에서 4개까지 출력하여 구조를 확인합니다.\n",
    "reshot_image_elements[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2af5649b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.reshot.com/build/photos/external-link-arrow-9fdf3fbf53535dc5eb554a9a5d5601329bb7bb7169ee72746a37fac0527b2967.svg'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. \"이미지 URL 추출 및 다운로드\" (Extract URL and Download) \n",
    "\n",
    "\n",
    "# 'reshot_image_elements' 리스트에서 두 번째 요소(인덱스 1)를 선택하고, \n",
    "# \".get('src')\" 메서드를 사용하여 해당 <img> 태그의 'src' 속성 값(실제 이미지 URL)을 추출합니다.\n",
    "reshot_image_url = reshot_image_elements[1].get('src')\n",
    "\n",
    "# 추출된 이미지 URL을 출력하여 확인합니다.\n",
    "reshot_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0c10367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"requests.get(reshot_image_url)\"을 사용하여 추출된 이미지 URL로 HTTP GET 요청을 보내고, \n",
    "# 이미지 바이너리 데이터를 포함하는 \"Response 객체\"를 'html_image'에 저장합니다. (다운로드 준비)\n",
    "html_image = requests.get(reshot_image_url)\n",
    "\n",
    "# 이미지를 저장할 로컬 폴더 경로를 정의합니다.\n",
    "# (이전에 해당 폴더가 생성되었는지 확인하는 코드는 생략되어 있으므로, 존재해야 오류가 발생하지 않습니다.)\n",
    "folder = \"C:/Myexam/download\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "525e0d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. \"스트리밍 파일 저장\" (Streaming File Save)\n",
    "\n",
    "\n",
    "# 파일 경로를 구성하여 파일을 \"쓰기 바이너리 모드('wb')\"로 엽니다.\n",
    "# \"os.path.join(folder, os.path.basename(reshot_image_url))\"은 \n",
    "# '폴더 경로'와 URL에서 추출한 '순수한 파일 이름'을 결합하여 최종 저장 경로를 만듭니다.\n",
    "imageFile = open(os.path.join(folder, os.path.basename(reshot_image_url)), 'wb')\n",
    "\n",
    "# 파일 저장 시 사용할 데이터 조각(청크)의 크기를 바이트 단위로 정의합니다. (1MB)\n",
    "chunk_size = 1000000 \n",
    "\n",
    "# 'html_image.iter_content(chunk_size)'를 사용하여 이미지 데이터를 청크 단위로 분할하여 반복합니다.\n",
    "# 이는 \"큰 파일\"을 메모리에 한 번에 로드하지 않고 스트리밍 방식으로 처리하는 데 효율적입니다.\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    # 반복문에서 얻은 데이터 조각(\"chunk\")을 열려 있는 파일 객체 'imageFile'에 \"쓰기\"를 수행합니다.\n",
    "    imageFile.write(chunk)\n",
    "\n",
    "# 모든 쓰기 작업이 완료되면, 'imageFile.close()'를 호출하여 파일을 \"닫고\" 시스템 자원을 해제합니다.\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "366f9e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 웹 이미지 일괄 다운로드 (함수로 만들어서 가져오기) ---\n",
    "\n",
    "\n",
    "# 1. \"함수 정의: 이미지 URL 추출 (get_image_url)\"\n",
    "\n",
    "def get_image_url(url): \n",
    "    # 1. HTML 소스 가져오기: requests.get()으로 요청 후 .text로 HTML 문자열을 얻습니다.\n",
    "    html_image_url = requests.get(url).text \n",
    "    \n",
    "    # 2. BeautifulSoup 객체 생성: HTML을 파싱(분석)하여 데이터 추출 준비를 합니다.\n",
    "    soup_image_url = BeautifulSoup(html_image_url, \"lxml\") \n",
    "    \n",
    "    # 3. 모든 <img> 태그 찾기: CSS 선택자 'img'를 사용하여 페이지의 모든 이미지 요소를 찾습니다.\n",
    "    image_elements = soup_image_url.select('img') \n",
    "    \n",
    "    # 4. 이미지 요소 존재 여부 확인: 요소 리스트가 비어있지 않은지 확인합니다.\n",
    "    if(image_elements != None):\n",
    "        image_urls = [] # 이미지 URL을 저장할 빈 리스트를 초기화합니다.\n",
    "        \n",
    "        # 5. URL 추출: 찾은 모든 <img> 태그에 대해 반복합니다.\n",
    "        for image_element in image_elements:\n",
    "            # \".get('src')\"를 사용하여 해당 태그의 'src' 속성 값(이미지 URL)을 추출해 리스트에 추가합니다.\n",
    "            image_urls.append(image_element.get('src'))\n",
    "            \n",
    "        return image_urls # 이미지 URL 리스트를 반환합니다.\n",
    "        \n",
    "    else: \n",
    "        return None # <img> 태그가 발견되지 않으면 None을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f20c26ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. \"함수 정의: 이미지 다운로드 (download_image)\"\n",
    "\n",
    "    \n",
    "def download_image(img_folder, img_url):\n",
    "    # img_folder: 이미지를 저장할 로컬 폴더 경로 (예: 'C:/Myexam/download')\n",
    "    # img_url: 다운로드할 이미지의 웹 URL\n",
    "    \n",
    "    # 1. URL 유효성 검사: img_url이 None이 아닌지 확인하여 유효한 URL이 있을 때만 다운로드 작업을 시작합니다.\n",
    "    if(img_url != None): \n",
    "        # 2. 이미지 데이터 요청: requests.get(img_url)을 사용하여 해당 URL로 HTTP GET 요청을 보냅니다.\n",
    "        #    서버로부터 이미지의 바이너리 데이터가 포함된 Response 객체를 'html_image'에 저장합니다.\n",
    "        html_image = requests.get(img_url)\n",
    "        \n",
    "        # 3. 파일 열기: os.path.join()을 사용하여 폴더 경로와 파일 이름(os.path.basename(img_url)으로 URL에서 추출)을 결합합니다.\n",
    "        #    open() 함수로 해당 경로에 파일을 \"쓰기 바이너리 모드('wb')\"로 열어 'imageFile' 객체를 만듭니다.\n",
    "        imageFile = open(os.path.join(img_folder, os.path.basename(img_url)), 'wb')\n",
    "        \n",
    "        # 4. 청크 크기 정의: 파일 저장을 위한 데이터 조각(청크)의 크기를 바이트 단위로 정의합니다. (1MB)\n",
    "        chunk_size = 1000000\n",
    "        \n",
    "        # 5. 스트리밍 저장 시작: html_image.iter_content(chunk_size)를 사용하여 이미지 데이터를 청크 단위로 읽어오며 반복합니다.\n",
    "        #    이는 큰 파일을 메모리에 한 번에 올리지 않아 \"메모리 효율적\"입니다.\n",
    "        for chunk in html_image.iter_content(chunk_size):\n",
    "            # 6. 데이터 쓰기: 읽어온 데이터 조각('chunk')을 'imageFile' 객체를 통해 디스크에 씁니다.\n",
    "            imageFile.write(chunk)\n",
    "            \n",
    "        # 7. 파일 닫기: 모든 청크 쓰기 작업이 완료되면, 'imageFile.close()'를 호출하여 파일을 \"닫고\" 시스템 자원을 해제합니다.\n",
    "        imageFile.close()\n",
    "        \n",
    "        # 8. 완료 메시지 출력: 다운로드 성공 메시지와 저장된 파일 이름을 출력합니다.\n",
    "        print(f\"이미지 파일명: '{os.path.basename(img_url)}'. 내려받기 완료!\") \n",
    "        \n",
    "    else: \n",
    "        # 9. URL이 None일 경우: 다운로드할 이미지가 없다는 메시지를 출력합니다.\n",
    "        print(\"내려받을 이미지가 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e31ca8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 파일명: 'reshot-logo--mark-f8dfafbc1cc8fbf4dfa0e2f210265735aefa6e32f883b5a1fe27fd94f84719b3.svg'. 내려받기 완료!\n",
      "이미지 파일명: 'icon-no-photos-034c2399566c35bc56688f11795abdadf83f3c88fd167216a17ed55c2d65c73e.svg'. 내려받기 완료!\n",
      "이미지 파일명: 'external-link-arrow-9fdf3fbf53535dc5eb554a9a5d5601329bb7bb7169ee72746a37fac0527b2967.svg'. 내려받기 완료!\n",
      "이미지 파일명: 'nue-royalty-free-462bfb6f00f39fa826d02345c88ad4f478f7c91e4b7e52b69bf90af33f51e9e7.png'. 내려받기 완료!\n",
      "이미지 파일명: 'elements-logo-a914a0d98bda174a3e606aba79073b9c3c2db5075d5742ce48d9fb58186c0858.svg'. 내려받기 완료!\n",
      "이미지 파일명: 'external-link-arrow-9fdf3fbf53535dc5eb554a9a5d5601329bb7bb7169ee72746a37fac0527b2967.svg'. 내려받기 완료!\n",
      "이미지 파일명: 'reshot-logo--mark-f8dfafbc1cc8fbf4dfa0e2f210265735aefa6e32f883b5a1fe27fd94f84719b3.svg'. 내려받기 완료!\n",
      "================================\n",
      "선택한 모든 이미지 내려받기 완료!\n"
     ]
    }
   ],
   "source": [
    "# 3. \"메인 실행 블록\" (Main Execution Block)\n",
    "\n",
    "\n",
    "# 1) URL 및 폴더 정의\n",
    "reshot_url = 'https://www.reshot.com/search/animal' # 이미지 소스 웹페이지 URL\n",
    "figure_folder = \"C:/Myexam/download\" # 이미지 저장 경로\n",
    "\n",
    "# 2) 이미지 URL 리스트 가져오기\n",
    "# get_image_url 함수를 호출하여 페이지의 모든 이미지 URL 리스트를 얻습니다.\n",
    "reshot_image_urls = get_image_url(reshot_url)\n",
    "\n",
    "# 3) 다운로드 횟수 설정\n",
    "# 리스트의 길이만큼 반복하기 위해 개수를 확인합니다.\n",
    "num_of_download_image = len(reshot_image_urls)\n",
    "\n",
    "# 4) 일괄 다운로드 실행\n",
    "# 리스트의 모든 URL에 대해 반복합니다. (0부터 num_of_download_image - 1까지)\n",
    "for k in range(num_of_download_image):\n",
    "    # download_image 함수를 호출하여 리스트의 각 URL에 해당하는 이미지를 다운로드합니다.\n",
    "    # \"download_image\" 함수의 오류 때문에, 이 코드를 실행하면 첫 이미지 다운로드 시 \"File I/O Error\"가 발생하거나,\n",
    "    # 다운로드가 불완전하게 끝날 수 있습니다.\n",
    "    download_image(figure_folder,reshot_image_urls[k])\n",
    "    \n",
    "# 5) 최종 완료 메시지\n",
    "print(\"================================\")\n",
    "print(\"선택한 모든 이미지 내려받기 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f5378dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 고양이 이미지 다운로드 ---\n",
    "\n",
    "\n",
    "url = 'https://i.pinimg.com/736x/d8/a6/cb/d8a6cbb02bc2c5c27ae238db2e89425d.jpg'\n",
    "\n",
    "html_image_jpg = requests.get(url)\n",
    "image_cat_file_name = os.path.basename(url)\n",
    "\n",
    "\n",
    "folder = 'C:/Myexam/download' \n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "image_path_cat = os.path.join(folder, image_cat_file_name)\n",
    "\n",
    "imageFile_cat = open(image_path_cat, 'wb')\n",
    "\n",
    "chunk_size = 1000000\n",
    "\n",
    "for chunk in html_image_jpg.iter_content(chunk_size):\n",
    "    imageFile_cat.write(chunk)\n",
    "\n",
    "imageFile_cat.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
