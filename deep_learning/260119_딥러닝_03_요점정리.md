# 딥러닝 분류 모델 비교: 이진 분류 vs 다중 분류

**`260107 딥러닝 03.py`** 파일은 기존의 이진 분류 모델(`01.py`, `02.py`)과 달리 **다중 클래스 분류(Multi-class Classification)** 문제를 다룹니다. 주요 차이점은 다음과 같습니다.

## 1. 타겟 데이터 변환 (One-Hot Encoding)

다중 분류에서는 정답(Target)이 0, 1, 2와 같은 단순 숫자가 아닌, 각 클래스에 대한 확률 벡터로 표현되어야 학습이 원활합니다.

- **이진 분류**: `0` 또는 `1` (하나의 숫자로 충분)
- **다중 분류**: `pd.get_dummies(y)`를 사용하여 문자열 카테고리를 벡터로 변환
  - 예: `"Iris-setosa"` → `[1, 0, 0]`
  - 예: `"Iris-versicolor"` → `[0, 1, 0]`

## 2. 출력층 구조 (Output Layer)

출력층의 뉴런 개수와 활성화 함수가 변경됩니다.

- **뉴런 개수**:

  - **이진 분류**: `Dense(1)` (결과가 0.7과 같이 하나만 나오면 됨)
  - **다중 분류**: `Dense(클래스 개수)` (여기서는 3개 품종이므로 `3`)

- **활성화 함수**:
  - **이진 분류**: `activation='sigmoid'` (0~1 사이의 독립된 확률값)
  - **다중 분류**: `activation='softmax'` (모든 출력의 합이 100%(1.0)가 되도록 비율 조정)

## 3. 오차 함수 (Loss Function)

모델이 예측값과 실제값의 차이를 계산하는 방식이 다릅니다.

- **이진 분류**: `loss='binary_crossentropy'`
- **다중 분류**: `loss='categorical_crossentropy'`

## 요약 비교표

| 구분            | 이진 분류 (Binary)    | 다중 분류 (Multi-class)        |
| :-------------- | :-------------------- | :----------------------------- |
| **코드 예시**   | `01.py`, `02.py`      | `03.py`                        |
| **타겟 형태**   | 0 또는 1 (스칼라)     | `[1, 0, 0]` (원-핫 벡터)       |
| **출력층 노드** | `Dense(1)`            | **`Dense(클래스 개수)`**       |
| **활성화 함수** | `sigmoid`             | **`softmax`**                  |
| **오차 함수**   | `binary_crossentropy` | **`categorical_crossentropy`** |
