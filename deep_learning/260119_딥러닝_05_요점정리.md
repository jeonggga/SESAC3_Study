# 모델 업데이트(ModelCheckpoint) 및 조기 종료(EarlyStopping)

**`260107 딥러닝 05.py`** 파일은 와인(Wine) 데이터셋을 활용한 **이진 분류** 예제입니다. 이 예제에서는 학습 과정 중 모델의 성능을 모니터링하여 **최적의 모델을 저장**하고, 성능이 더 이상 향상되지 않을 때 **학습을 미리 중단**하는 방법을 다룹니다.

## 1. 모델 성능 모니터링과 체크포인트 (ModelCheckpoint)

딥러닝 학습 시 Epoch마다 성능(정확도, 오차)이 달라집니다. 학습 도중 가장 성능이 좋았던 순간의 모델을 저장하기 위해 `ModelCheckpoint` 콜백(Callback) 함수를 사용합니다.

- **핵심 파라미터**:
  - `filepath`: 모델을 저장할 경로 (파일명에 `{epoch}`, `{val_loss}` 등 변수 사용 가능)
  - `monitor`: 모니터링할 지표 (주로 `'val_loss'` 사용)
  - `save_best_only=True`: 이전에 저장된 모델보다 성능이 좋을 때만 덮어씀

```python
from tensorflow.keras.callbacks import ModelCheckpoint

# 예: val_loss가 개선될 때만 bestmodel.keras로 저장
checkpointer = ModelCheckpoint(filepath='path/to/bestmodel.keras', monitor='val_loss', save_best_only=True)
model.fit(..., callbacks=[checkpointer])
```

## 2. 학습 자동 중단 (EarlyStopping)

과적합(Overfitting)을 방지하고 불필요한 학습 시간을 줄이기 위해 사용합니다. 테스트 오차(`val_loss`)가 줄어들지 않고 계속 증가하거나 정체될 때 학습을 자동으로 멈춥니다.

- **핵심 파라미터**:
  - `monitor='val_loss'`: 테스트셋 오차를 감시
  - `patience=20`: 오차가 줄어들지 않아도 20번의 Epoch까지는 기다려봄 (그래도 안 줄면 중단)

```python
from tensorflow.keras.callbacks import EarlyStopping

early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)
model.fit(..., callbacks=[early_stopping_callback])
```

## 3. 학습 과정 시각화

학습 데이터셋의 오차(`loss`)와 테스트 데이터셋의 오차(`val_loss`)를 그래프로 그려 과적합 여부를 눈으로 확인합니다.

- **Trainset_loss (파란색)**: 학습이 진행될수록 계속 감소
- **Testset_loss (빨간색)**: 어느 순간부터 감소하다가 다시 증가하면 **과적합** 시작

```python
# history 객체에서 loss 정보 추출 및 그래프 그리기
y_vloss = history.history['val_loss']
y_loss = history.history['loss']
plt.plot(x_len, y_vloss, c="red", label='Testset_loss')
plt.plot(x_len, y_loss, c="blue", label='Trainset_loss')
```

## 4. 실습 코드 흐름 요약

1. **데이터 로드**: 와인 데이터 (레드 vs 화이트)
2. **기본 학습**: 콜백 없이 일반적인 학습 진행 (`validation_split=0.25`로 검증셋 자동 분리)
3. **체크포인트 실습**: 모든 Epoch마다 모델을 파일로 저장하며 성능 기록 확인
4. **그래프 시각화**: 과적합이 일어나는 지점을 그래프로 확인
5. **최적화 학습 (Best Practice)**:
   - `ModelCheckpoint`: 최고 성능 모델만 저장
   - `EarlyStopping`: 과적합 징후 시 학습 조기 종료
   - 이 두 가지를 동시에 적용하여 최적의 모델 확보
