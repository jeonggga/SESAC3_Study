{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0534dd14",
   "metadata": {},
   "source": [
    "### Sklearn 실습 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85399eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_iris  # 붓꽃(Iris) 데이터 세트를 불러오기 위한 함수\n",
    "from sklearn.tree import DecisionTreeClassifier  # 의사결정트리(Decision Tree) 분류 알고리즘 클래스\n",
    "from sklearn.metrics import accuracy_score  # 모델의 성능(정확도)을 평가하기 위한 함수\n",
    "from sklearn.model_selection import train_test_split  # 학습 데이터와 테스트 데이터를 분리하는 함수\n",
    "from sklearn.model_selection import KFold  # K-Fold 교차 검증을 위한 클래스\n",
    "from sklearn.model_selection import StratifiedKFold  # 레이블 불균형을 해결한 K-Fold 클래스\n",
    "from sklearn.model_selection import cross_val_score, cross_validate  # 교차 검증을 간편하게 수행하는 API\n",
    "from sklearn.model_selection import GridSearchCV  # 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에 수행하는 클래스\n",
    "import pandas as pd  # 데이터를 표(DataFrame) 형태로 다루기 위한 라이브러리\n",
    "import numpy as np  # 수치 연산 및 배열(ndarray) 처리를 위한 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3276159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:  1.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. 데이터 로드 및 학습 데이터로만 학습/예측 (과적합 문제 발생 예시)\n",
    "# ==========================================\n",
    "\n",
    "# 붓꽃 데이터 세트를 로딩합니다.\n",
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# 데이터를 별도의 테스트 세트로 나누지 않고, 전체 데이터를 학습 데이터로 사용합니다.\n",
    "# 이렇게 하면 모델이 이미 본 데이터로 시험을 치르는 것이므로 과적합(Overfitting)이 발생합니다.\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "dt_clf.fit(train_data, train_label)\n",
    "\n",
    "# 학습된 데이터로 다시 예측을 수행합니다.\n",
    "# 이미 답을 알고 있는 데이터로 시험을 보는 것과 같으므로 정확도가 1.0(100%)이 나옵니다.\n",
    "pred = dt_clf.predict(train_data)\n",
    "print('예측 정확도: ', accuracy_score(train_label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "964833b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9556\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 2. train_test_split을 이용한 학습/테스트 데이터 분리\n",
    "# ==========================================\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "iris_data = iris.data\n",
    "\n",
    "# test_size=0.3: 전체 데이터의 30%를 테스트 데이터로 분리합니다. (학습 70%, 테스트 30%)\n",
    "# random_state=121: 난수 시드를 고정하여 코드를 실행할 때마다 항상 동일하게 데이터가 섞이도록 합니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris.target, test_size=0.3, random_state=121)\n",
    "\n",
    "# 분리된 학습 데이터(X_train, y_train)로만 학습을 수행합니다.\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# 학습에 사용하지 않은 테스트 데이터(X_test)로 예측을 수행하고 정확도를 확인합니다.\n",
    "pred = dt_clf.predict(X_test)\n",
    "print(f'예측 정확도: {accuracy_score(y_test, pred):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96801c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n",
      "예측 정확도: 0.9556\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. DataFrame을 이용한 데이터 분할 실습\n",
    "# ==========================================\n",
    "\n",
    "# 붓꽃 데이터를 보기 좋게 DataFrame으로 변환합니다.\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "print(iris_df.head())\n",
    "\n",
    "# 피처 데이터(마지막 'target' 열 제외)와 타겟 데이터(마지막 'target' 열)를 분리합니다.\n",
    "ftr_df = iris_df.iloc[:, :-1]\n",
    "tgt_df = iris_df.iloc[:, -1]\n",
    "\n",
    "# DataFrame 형태의 데이터도 train_test_split으로 바로 분리가 가능합니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(ftr_df, tgt_df, test_size=0.3, random_state=121)\n",
    "\n",
    "print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "\n",
    "# DataFrame으로 분리된 데이터로 학습 및 예측을 수행합니다.\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print(f'예측 정확도: {accuracy_score(y_test, pred):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfe697bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기:  150\n",
      "#1 정확도: 1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "# 1 검증 세트 인덱스: 1 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "#2 정확도: 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "# 2 검증 세트 인덱스: 2 [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "#3 정확도: 0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "# 3 검증 세트 인덱스: 3 [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "#4 정확도: 0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "# 4 검증 세트 인덱스: 4 [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "#5 정확도: 0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "# 5 검증 세트 인덱스: 5 [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      " ## 평균 검증 정확도:  0.9\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. K-Fold 교차 검증 (K-Fold Cross Validation)\n",
    "# ==========================================\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트 크기: ', features.shape[0])\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 KFold 객체 생성\n",
    "n_iter = 0\n",
    "\n",
    "\n",
    "# KFold 객체의 split()을 호출하면 전체 데이터를 5등분하여 학습용/검증용 데이터의 인덱스를 반환합니다.\n",
    "for train_index, test_index in KFold().split(features):\n",
    "    # 반환된 인덱스를 이용하여 학습용(Train), 검증용(Test) 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    # 반복마다 모델을 초기화하지는 않았지만, fit()을 호출하면 새로운 데이터로 학습하게 됩니다.\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    n_iter += 1\n",
    "\n",
    "    # 정확도 계산 및 출력\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print(f'#{n_iter} 정확도: {accuracy}, 학습 데이터 크기: {train_size}, 검증 데이터 크기: {test_size}')\n",
    "    print(f'# {n_iter} 검증 세트 인덱스: {n_iter} {test_index}')\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "# 5개 폴드의 평균 정확도를 계산하여 모델의 일반화 성능을 평가합니다.\n",
    "print('\\n ## 평균 검증 정확도: ', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "517dea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "## 교차 검증 1\n",
      "학습 레이블 빈도수: \n",
      "label\n",
      "1    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 빈도수: \n",
      "label\n",
      "0    50\n",
      "Name: count, dtype: int64\n",
      "## 교차 검증 2\n",
      "학습 레이블 빈도수: \n",
      "label\n",
      "0    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 빈도수: \n",
      "label\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "## 교차 검증 3\n",
      "학습 레이블 빈도수: \n",
      "label\n",
      "0    50\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 빈도수: \n",
      "label\n",
      "2    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 5. K-Fold의 문제점 확인 (데이터 불균형 문제)\n",
    "# ==========================================\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "\n",
    "# 원본 데이터의 레이블 분포 확인 (0, 1, 2가 각 50개씩 균등함)\n",
    "print(iris_df['label'].value_counts())\n",
    "\n",
    "# 데이터를 순서대로 3등분 하는 일반 K-Fold의 경우, 특정 레이블이 학습/검증 세트에서 배제될 수 있습니다.\n",
    "kfold = KFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    n_iter += 1\n",
    "    \n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    \n",
    "    # 학습 레이블과 검증 레이블의 분포를 출력하여 불균형을 확인합니다.\n",
    "    # 예: 학습엔 0, 1만 있고 검증엔 2만 있는 경우 학습이 제대로 되지 않습니다.\n",
    "    print(f'## 교차 검증 {n_iter}')\n",
    "    print(f'학습 레이블 빈도수: \\n{label_train.value_counts()}')\n",
    "    print(f'검증 레이블 빈도수: \\n{label_test.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ab18d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Stratified 교차 검증 1\n",
      "학습 레이블 분포: \n",
      "label\n",
      "2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 분포: \n",
      "label\n",
      "0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: count, dtype: int64\n",
      "#1 교차 검증 정확도: 0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "\n",
      "## Stratified 교차 검증 2\n",
      "학습 레이블 분포: \n",
      "label\n",
      "1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 분포: \n",
      "label\n",
      "0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: count, dtype: int64\n",
      "#2 교차 검증 정확도: 0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "\n",
      "## Stratified 교차 검증 3\n",
      "학습 레이블 분포: \n",
      "label\n",
      "0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 분포: \n",
      "label\n",
      "1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: count, dtype: int64\n",
      "#3 교차 검증 정확도: 0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "\n",
      "## Stratified K-Fold 교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "## Stratified K-Fold 평균 검증 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. Stratified K-Fold (불균형한 분포를 가진 데이터에 적합)\n",
    "# ==========================================\n",
    "\n",
    "# StratifiedKFold는 불균형한 분포를 가진 레이블(Target) 데이터 집합을 위한 K-Fold 방식입니다.\n",
    "# 원본 데이터의 레이블 분포를 먼저 고려한 뒤, 이 분포와 동일하게 학습/검증 데이터 세트를 분배합니다.\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 3개의 폴드로 나누며, Stratified 방식을 사용합니다.\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "# StratifiedKFold의 split() 호출 시 반드시 레이블 데이터셋(label)도 함께 넣어주어야 분포를 파악할 수 있습니다.\n",
    "# (iris_df는 위 5번 예제에서 생성한 DataFrame을 그대로 사용)\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter += 1\n",
    "    \n",
    "    # 1. 데이터 분할\n",
    "    # 데이터프레임에서 인덱스를 사용해 학습/검증 데이터를 나눕니다.\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    \n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # [검증] K-Fold와 달리 모든 폴드에서 레이블이 균일한 비율로 섞여 있음을 확인합니다.\n",
    "    print(f'\\n## Stratified 교차 검증 {n_iter}')\n",
    "    print(f'학습 레이블 분포: \\n{label_train.value_counts()}')\n",
    "    print(f'검증 레이블 분포: \\n{label_test.value_counts()}')\n",
    "    \n",
    "    # 2. 모델 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    # 3. 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    print(f'#{n_iter} 교차 검증 정확도: {accuracy}, 학습 데이터 크기: {train_size}, 검증 데이터 크기: {test_size}')\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "# 교차 검증별 정확도 및 평균 정확도 출력\n",
    "print('\\n## Stratified K-Fold 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
    "print(f'## Stratified K-Fold 평균 검증 정확도: {np.mean(cv_accuracy):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df33fc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[cross_val_score 수행 결과]\n",
      "교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "평균 검증 정확도: 0.9667\n",
      "\n",
      "[cross_validate 수행 결과 (딕셔너리 형태)]\n",
      "반환된 키 목록: dict_keys(['fit_time', 'score_time', 'test_score'])\n",
      "테스트 정확도(test_score): [0.98 0.94 0.98]\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 7. cross_val_score (교차 검증을 간편하게 수행하는 API)\n",
    "# ==========================================\n",
    "    \n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target   \n",
    "\n",
    "# cross_val_score: 위에서 for문으로 작성한 교차 검증 과정을 한 줄로 줄여줍니다.\n",
    "# 특징 1: 내부적으로 Stratified K-Fold를 사용하여 레이블 분포를 유지합니다. (분류 모델인 경우)\n",
    "# 특징 2: 교차 검증 후의 정확도(score)를 배열 형태로 반환합니다.\n",
    "# cv=3 : 3개의 폴드로 나눔. scoring='accuracy' : 평가지표로 정확도를 사용.\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "\n",
    "print('\\n[cross_val_score 수행 결과]')\n",
    "print(f'교차 검증별 정확도: {np.round(scores, 4)}')\n",
    "print(f'평균 검증 정확도: {np.round(np.mean(scores), 4)}')\n",
    "\n",
    "# [보너스] cross_validate: 여러 개의 평가지표를 한 번에 확인하고 싶을 때 사용\n",
    "# 반환값이 딕셔너리 형태라 {키: [값, 값, 값]} 구조를 가집니다.\n",
    "scores2 = cross_validate(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "print('\\n[cross_validate 수행 결과 (딕셔너리 형태)]')\n",
    "print(\"반환된 키 목록:\", scores2.keys())\n",
    "print(\"테스트 정확도(test_score):\", np.round(scores2['test_score'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2163265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[GridSearchCV 수행 결과]\n",
      "                                     params  mean_test_score  rank_test_score  \\\n",
      "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
      "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
      "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
      "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
      "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
      "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
      "\n",
      "   split0_test_score  split1_test_score  split2_test_score  \n",
      "0              0.700                0.7               0.70  \n",
      "1              0.700                0.7               0.70  \n",
      "2              0.925                1.0               0.95  \n",
      "3              0.925                1.0               0.95  \n",
      "4              0.975                1.0               0.95  \n",
      "5              0.975                1.0               0.95  \n",
      "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최적 정확도: 0.9750\n",
      "테스트 데이터 세트 정확도 (grid_dtree 바로 사용): 0.9667\n",
      "테스트 데이터 세트 정확도 (best_estimator_ 사용): 0.9667\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 8. GridSearchCV (교차 검증과 하이퍼파라미터 튜닝을 동시에)\n",
    "# ==========================================\n",
    "\n",
    "iris = load_iris()\n",
    "# 테스트 데이터를 20% 별도로 분리해 둡니다. (나중에 최종 성능 평가용)\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# 파라미터 딕셔너리 설정\n",
    "# max_depth: 트리의 최대 깊이, min_samples_split: 노드를 분할하기 위한 최소 샘플 수\n",
    "parameters = {'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]}\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "# param_grid: 튜닝할 파라미터들\n",
    "# cv=3: 3-Fold 교차 검증 수행\n",
    "# refit=True: 최적의 파라미터를 찾으면, 그 파라미터로 전체 학습 데이터(X_train)에 대해 다시 학습(refit)을 수행\n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "\n",
    "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터들을 순차적으로 학습/평가\n",
    "# 이 과정에서 모든 파라미터 조합에 대해 CV를 수행하고 가장 좋은 파라미터를 찾습니다.\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "print('\\n[GridSearchCV 수행 결과]')\n",
    "# GridSearchCV 결과는 cv_results_ 딕셔너리에 저장됩니다. DataFrame으로 변환하여 확인.\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "print(scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']])\n",
    "\n",
    "# 최적의 파라미터와 그때의 정확도 확인\n",
    "print(f'GridSearchCV 최적 파라미터: {grid_dtree.best_params_}')\n",
    "print(f'GridSearchCV 최적 정확도: {grid_dtree.best_score_:.4f}')\n",
    "\n",
    "# refit=True로 설정했으므로 grid_dtree 객체 자체가 이미 최적의 파라미터로 재학습된 Estimator 역할을 할 수 있습니다.\n",
    "# 바로 predict()를 호출하면 내부적으로 최적의 모델을 사용하여 예측을 수행합니다.\n",
    "pred = grid_dtree.predict(X_test)\n",
    "print(f'테스트 데이터 세트 정확도 (grid_dtree 바로 사용): {accuracy_score(y_test, pred):.4f}')\n",
    "\n",
    "# 또는 best_estimator_ 속성을 통해 최적의 모델(Estimator) 객체만 따로 꺼내와서 사용할 수도 있습니다.\n",
    "estimator = grid_dtree.best_estimator_\n",
    "pred = estimator.predict(X_test)\n",
    "print(f'테스트 데이터 세트 정확도 (best_estimator_ 사용): {accuracy_score(y_test, pred):.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
