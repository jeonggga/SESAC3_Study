{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed8e3038",
   "metadata": {},
   "source": [
    "### Sklearn 실습 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7512df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder  # 카테고리형 피처를 숫자형으로 변환 (Label Encoding)\n",
    "from sklearn.preprocessing import OneHotEncoder  # 카테고리형 피처를 원-핫 인코딩으로 변환\n",
    "from sklearn.preprocessing import StandardScaler  # 평균 0, 분산 1로 변환 (표준화)\n",
    "from sklearn.preprocessing import MinMaxScaler  # 0과 1 사이의 값으로 변환 (정규화)\n",
    "from sklearn.datasets import load_iris  # 붓꽃 데이터셋 로드\n",
    "import numpy as np  # 수치 연산\n",
    "import pandas as pd  # 데이터프레임 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1a91c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값: [0 1 4 5 3 3 2 2]\n",
      "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n",
      "디코딩 원본 값: ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. 레이블 인코딩 (Label Encoding)\n",
    "# ==========================================\n",
    "# 문자열(String)로 된 카테고리형 데이터를 숫자(Number)로 변환합니다.\n",
    "# TV -> 0, 냉장고 -> 1, ... 이런 식으로 매핑됩니다.\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# LabelEncoder 객체 생성\n",
    "encoder = LabelEncoder()\n",
    "# 1. fit(): 데이터의 고유한 값(Unique Value)을 찾아 정렬하고 인코딩 규칙을 학습합니다.\n",
    "encoder.fit(items)\n",
    "\n",
    "# 2. transform(): 학습된 규칙에 따라 실제 데이터를 숫자로 변환합니다.\n",
    "labels = encoder.transform(items)\n",
    "print(f'인코딩 변환값: {labels}')  # [0 1 4 5 3 3 2 2] 등 정렬 순서대로 0부터 번호 부여\n",
    "\n",
    "# classes_ 속성에는 인코딩된 문자열 원본이 정렬된 순서대로 들어있습니다. (0번부터 순서대로)\n",
    "print(f'인코딩 클래스: {encoder.classes_}')\n",
    "\n",
    "# inverse_transform(): 인코딩된 숫자를 다시 원본 문자열로 복구(디코딩)합니다.\n",
    "print(f'디코딩 원본 값: {encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ee9c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원-핫 인코딩 변환값: \n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원-핫 인코딩 데이터 차원: (8, 6)\n",
      "\n",
      "[Pandas get_dummies 결과]\n",
      "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
      "0     True     False    False     False       False     False\n",
      "1    False      True    False     False       False     False\n",
      "2    False     False    False     False        True     False\n",
      "3    False     False    False     False       False      True\n",
      "4    False     False    False      True       False     False\n",
      "5    False     False    False      True       False     False\n",
      "6    False     False     True     False       False     False\n",
      "7    False     False     True     False       False     False\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 2. 원-핫 인코딩 (One-Hot Encoding)\n",
    "# ==========================================\n",
    "# 레이블 인코딩의 문제점(숫자 크기가 의미를 가짐 -> 1등, 2등 처럼 인식)을 해결하기 위해 사용합니다.\n",
    "# 고유한 값의 개수만큼 컬럼을 만들고, 해당되는 컬럼에만 1, 나머지는 0을 표시합니다. (희소 행렬 형태)\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# 먼저 숫자값으로 변환을 위해 LabelEncoder 사용\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "\n",
    "# 2차원 데이터로 변환해야 OneHotEncoder에 넣을 수 있습니다. (-1은 '나머지 차원은 알아서 맞춰라'는 뜻)\n",
    "labels = labels.reshape(-1, 1)\n",
    "\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "\n",
    "# toarray()를 사용해 희소 행렬(Sparse Matrix)을 밀집 행렬(Dense Matrix)로 변환해 눈으로 확인합니다.\n",
    "print(f'원-핫 인코딩 변환값: \\n{oh_labels.toarray()}')\n",
    "print(f'원-핫 인코딩 데이터 차원: {oh_labels.shape}') \n",
    "\n",
    "\n",
    "# Pandas의 get_dummies()를 사용하면 훨씬 간편하게 원-핫 인코딩을 할 수 있습니다.\n",
    "# (별도의 숫자 변환 과정 없이 문자열 데이터를 바로 처리해 줍니다.)\n",
    "df = pd.DataFrame(items, columns=['item']) # 주의: 컬럼명 딕셔너리가 아닌 리스트로 수정\n",
    "print('\\n[Pandas get_dummies 결과]')\n",
    "print(pd.get_dummies(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c895b2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[StandardScaler 적용 전]\n",
      "feature 들의 평균 값: \n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "feature 들의 분산 값: \n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n",
      "\n",
      "[StandardScaler 적용 후]\n",
      "feature 들의 평균 값: \n",
      "-1.4684549872375404e-15\n",
      "feature 들의 분산 값: \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. 피처 스케일링 (Feature Scaling) - StandardScaler\n",
    "# ==========================================\n",
    "# 데이터를 평균 0, 분산 1인 정규 분포(가우시안 분포) 형태로 변환합니다.\n",
    "# SVM, 선형 회귀, 로지스틱 회귀 등에서 성능 향상에 도움이 됩니다.\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(iris_data, columns=iris.feature_names)\n",
    "\n",
    "print('\\n[StandardScaler 적용 전]')\n",
    "print(f'feature 들의 평균 값: \\n{iris_df.mean()}')\n",
    "print(f'feature 들의 분산 값: \\n{iris_df.var()}')\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# fit()으로 데이터의 평균과 분산을 계산하고, transform()으로 변환합니다.\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# transform 시 반환값은 ndarray이므로 보기 좋게 DataFrame으로 변환\n",
    "# iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "\n",
    "print('\\n[StandardScaler 적용 후]')\n",
    "print(f'feature 들의 평균 값: \\n{iris_scaled.mean()}') # 0에 매우 가까운 값\n",
    "print(f'feature 들의 분산 값: \\n{iris_scaled.var()}')  # 1에 매우 가까운 값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd1675ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MinMaxScaler 적용 후]\n",
      "feature 들의 최소 값: 0.0\n",
      "feature 들의 최대 값: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. 피처 스케일링 (Feature Scaling) - MinMaxScaler\n",
    "# ==========================================\n",
    "# 데이터 값을 0과 1 사이의 범위로 변환합니다. (음수가 있으면 -1 ~ 1)\n",
    "# 데이터 분포가 정규 분포가 아닐 때 유용합니다.\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "print('\\n[MinMaxScaler 적용 후]')\n",
    "print(f'feature 들의 최소 값: {iris_scaled.min()}') # 0.0\n",
    "print(f'feature 들의 최대 값: {iris_scaled.max()}') # 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de5ea9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 5. 스케일링 시 주의사항 (Data Leakage 방지)\n",
    "# ==========================================\n",
    "# 학습 데이터(Train)와 테스트 데이터(Test)를 스케일링할 때 가장 중요한 원칙:\n",
    "# \"학습 데이터의 기준(fit)을 테스트 데이터에도 똑같이 적용해야 한다!\"\n",
    "\n",
    "train_array = np.arange(0, 11).reshape(-1, 1) # 0부터 10까지\n",
    "test_array = np.arange(0, 6).reshape(-1, 1)  # 0부터 5까지\n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 1. 학습 데이터로 fit(): 학습 데이터의 최솟값(0), 최댓값(10)을 찾습니다.\n",
    "scaler.fit(train_array)\n",
    "# 2. 학습 데이터 transform(): 0~10을 0~1로 변환합니다. (10 -> 1.0)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print(f'\\n원본 train_array 데이터: {np.round(train_array.reshape(-1), 2)}')\n",
    "print(f'Scale된 train_array 데이터: {np.round(train_scaled.reshape(-1), 2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ca26b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[잘못된 예] 원본 test_array 데이터: [0 1 2 3 4 5]\n",
      "[잘못된 예] Scale된 test_array 데이터: [0.  0.2 0.4 0.6 0.8 1. ]\n",
      "\n",
      "[올바른 예] 원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "[올바른 예] Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "\n",
      "[올바른 예] 원본 test_array 데이터: [0 1 2 3 4 5]\n",
      "[올바른 예] Scale된 test_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "# [잘못된 예시] 테스트 데이터로 다시 fit()을 수행하는 경우\n",
    "# 테스트 데이터(0~5)를 기준으로 새로운 척도를 만들어버립니다. (5 -> 1.0)\n",
    "# 이렇게 되면 학습 데이터의 1.0(100점)과 테스트 데이터의 1.0(50점)이 서로 다른 의미를 가지게 되어 모델이 혼란스러워합니다.\n",
    "scaler.fit(test_array)\n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "print(f'\\n[잘못된 예] 원본 test_array 데이터: {np.round(test_array.reshape(-1), 2)}')\n",
    "print(f'[잘못된 예] Scale된 test_array 데이터: {np.round(test_scaled.reshape(-1), 2)}')\n",
    "\n",
    "\n",
    "# [올바른 예시] 학습 데이터 때 fit()한 scaler 객체를 그대로 사용하여 transform()만 수행해야 합니다.\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print(f'\\n[올바른 예] 원본 train_array 데이터: {np.round(train_array.reshape(-1), 2)}')\n",
    "print(f'[올바른 예] Scale된 train_array 데이터: {np.round(train_scaled.reshape(-1), 2)}')\n",
    "\n",
    "# 테스트 데이터는 절대 fit() 하지 않고 바로 transform() 만 합니다!\n",
    "# 그래야 \"학습 데이터의 10점이 1.0이니까, 테스트 데이터의 5점은 0.5구나\" 하고 올바르게 번역됩니다.\n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "print(f'\\n[올바른 예] 원본 test_array 데이터: {np.round(test_array.reshape(-1), 2)}')\n",
    "print(f'[올바른 예] Scale된 test_array 데이터: {np.round(test_scaled.reshape(-1), 2)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
