# 머신러닝 모델 상세 요약 보고서

본 문서는 `004 머신러닝_모델.pdf`의 내용을 바탕으로 머신러닝 주요 모델과 핵심 개념, 그리고 **주요 하이퍼파라미터**를 상세하게 정리한 것입니다.

---

## 1. 머신러닝 모델의 체계 (Hierarchy)

머신러닝 모델은 학습 방식에 따라 크게 **지도 학습(Supervised Learning)**, **비지도 학습(Unsupervised Learning)**, **강화 학습(Reinforcement Learning)**으로 나뉩니다. 본 문서에서는 지도 학습과 비지도 학습의 주요 모델들을 다룹니다.

### 주요 알고리즘 선택 기준

모델을 선택하고 구현할 때는 다음 요소를 종합적으로 고려해야 합니다.

- **시간 복잡도**: 해를 계산하는 데 걸리는 시간.
- **공간 복잡도**: 계산 시 소요되는 메모리 용량.
- **해의 안정성**: 입력값의 작은 변동에도 예측값이 크게 흔들리지 않아야 함.

---

## 2. 지도 학습 모델 (Supervised Learning)

지도 학습은 정답(Label)이 주어진 데이터를 학습하여 미지의 데이터에 대한 정답을 예측하는 방법입니다.

### 2.1 선형 모델 (Linear Models)

입력 변수(피처)들의 선형 결합($y = w_1x_1 + w_2x_2 + ... + b$)으로 타겟을 예측합니다.

#### ① 최소 제곱법 (Ordinary Least Squares, OLS)

- **개념**: 예측값과 실제값의 차이인 **잔차(Residual)의 제곱합을 최소화**하는 파라미터(가중치)를 찾는 가장 기본적인 회귀 모델입니다.
- **특징**: `StandardScaler` 등을 통한 피처 스케일링이 필요하며, 데이터에 특이값(Outlier)이 많으면 성능이 저하될 수 있습니다.

#### ② 릿지 회귀 (Ridge Regression) - L2 규제

- **개념**: OLS의 비용 함수에 **가중치들의 제곱합(L2 Penalty)**을 더해, 가중치가 너무 커지는 것을 방지하는 모델입니다.
- **효과**: 모든 피처의 영향력을 골고루 낮추어 **과적합(Overfitting)**을 방지하고 모델을 안정화합니다.
- **주요 하이퍼파라미터 (`Ridge`)**:
  - `alpha`: 규제 강도. 값이 클수록 규제가 강해져(계수가 0에 가까워짐) 과소적합 위험이 커지고, 작을수록 과적합 위험이 커집니다. (기본값: 1.0)
  - `solver`: 최적화 문제 알고리즘 선택 (`auto`, `svd`, `cholesky`, `lsqr`, `sparse_cg` 등).

#### ③ 라쏘 회귀 (Lasso Regression) - L1 규제

- **개념**: OLS의 비용 함수에 **가중치들의 절댓값 합(L1 Penalty)**을 더하는 방식입니다.
- **효과**: 중요하지 않은 변수의 가중치를 **완전히 0**으로 만들 수 있습니다. 따라서 **자동적인 피처 선택(Feature Selection)** 효과가 있어, 변수가 많은 희소(Sparse) 데이터셋에서 유용합니다.
- **주요 하이퍼파라미터 (`Lasso`)**:
  - `alpha`: 규제 강도. 릿지와 마찬가지로 값이 클수록 규제가 강해집니다. (기본값: 1.0)

#### ④ 로지스틱 회귀 (Logistic Regression)

- **개념**: 이름은 '회귀'지만 실제로는 **이진 분류(Binary Classification)**에 사용되는 모델입니다. 선형 방정식의 결과를 **시그모이드(Sigmoid) 함수**에 통과시켜 0과 1 사이의 확률값으로 변환합니다.
- **특징**: 선형 경계로 클래스를 나누므로, 데이터가 선형적으로 분리될 수 있을 때 성능이 좋습니다.
- **주요 하이퍼파라미터 (`LogisticRegression`)**:
  - `penalty`: 규제 유형 (`l1`, `l2`, `elasticnet`, `none`). (기본값: `l2`)
  - `C`: 규제 강도의 역수(`1/alpha`). **값이 작을수록 규제가 강합니다**. (기본값: 1.0)
  - `solver`: 최적화 알고리즘 (`lbfgs`, `liblinear`, `newton-cg`, `sag`, `saga`). 작은 데이터셋에는 `liblinear`, 대용량에는 `sag`, `saga`가 적합합니다.

### 2.2 트리 기반 모델 (Tree-based Models)

#### ① 결정 트리 (Decision Tree)

- **개념**: 스무고개 하듯이 데이터를 특정 기준(질문)에 따라 계속 분할해 나가는 방식입니다.
- **장점**: 데이터의 스케일에 영향을 받지 않아 **전처리(정규화)가 필요 없고**, 모델의 판단 과정을 시각화하여 이해하기 쉽습니다.
- **단점**: 훈련 데이터에 너무 깊게 맞춰 학습하면 새로운 데이터에 취약한 **과적합**이 쉽게 발생합니다.
- **주요 하이퍼파라미터 (`DecisionTreeClassifier`/`Regressor`)**:
  - `max_depth`: 트리의 최대 깊이. 깊을수록 과적합 위험이 큽니다.
  - `min_samples_split`: 노드를 분할하기 위해 필요한 최소 샘플 수.
  - `min_samples_leaf`: 잎 노드(Leaf Node)가 되기 위해 필요한 최소 샘플 수.
  - `max_features`: 최적의 분할을 찾기 위해 고려할 피처의 수.

#### ② 랜덤 포레스트 (Random Forest) - Bagging

- **개념**: 여러 개의 결정 트리를 만들고 그 결과들을 종함하여 최종 예측을 하는 앙상블 기법입니다.
- **원리**: 각 트리는 전체 데이터가 아닌 **부트스트랩(Bootstrap)**된 데이터로 학습합니다.
- **효과**: 단일 결정 트리의 높은 분산(과적합)을 줄입니다.
- **주요 하이퍼파라미터 (`RandomForestClassifier`/`Regressor`)**:
  - `n_estimators`: 생성할 결정 트리의 개수. 많을수록 성능이 좋아지지만 시간이 오래 걸립니다. (보통 100 이상)
  - `max_depth`, `min_samples_split`, `min_samples_leaf`: 개별 트리의 가지치기 파라미터 (결정 트리와 동일).
  - `n_jobs`: 병렬 처리에 사용할 CPU 코어 수 (`-1`이면 모든 코어 사용).

#### ③ 그레이디언트 부스팅 트리 (Gradient Boosting Tree, GBT) - Boosting

- **개념**: 여러 개의 약한 학습기(모델)를 **순차적으로 연결**하는 방식입니다. 앞선 모델이 **틀린 오차(잔차)를 다음 모델이 학습**하여 점진적으로 성능을 개선합니다.
- **주요 하이퍼파라미터 (`GradientBoostingClassifier`/`Regressor`)**:
  - `n_estimators`: 약한 학습기의 개수.
  - `learning_rate` (학습률): 각 트리가 기여하는 정도. **`n_estimators`와 반비례 관계**로 설정하는 것이 좋습니다 (학습률을 낮추면 트리 개수를 늘려야 함).
  - `subsample`: 각 트리를 학습할 때 사용할 데이터 샘플의 비율 (과적합 방지).

### 2.3 기타 지도 학습 모델

#### ① K-최근접 이웃 (K-Nearest Neighbors, KNN)

- **개념**: 새로운 데이터가 들어오면 기존 데이터 중 **가장 가까운 K개**를 찾아 분류하거나 예측합니다. 스케일링이 필수입니다.
- **주요 하이퍼파라미터 (`KNeighborsClassifier`/`Regressor`)**:
  - `n_neighbors`: 이웃의 수 K. K가 작으면 모델이 복잡해져 과적합 위험, K가 너무 크면 단순해져 과소적합 위험.
  - `weights`: 예측에 사용할 가중치 (`uniform`: 균일, `distance`: 거리에 반비례).
  - `metric`: 거리 측정 방식 (`minkowski`, `euclidean`, `manhattan`).

#### ② 서포트 벡터 머신 (Support Vector Machine, SVM)

- **개념**: 데이터 클래스를 나누는 가장 넓은 마진을 갖는 **결정 경계**를 찾는 모델입니다.
- **주요 하이퍼파라미터 (`SVC`/`SVR`)**:
  - `C`: 오류 허용 범위. 값이 크면 하드 마진(오류 허용 X, 과적합 위험), 작으면 소프트 마진(오류 허용 O, 과소적합 위험).
  - `kernel`: 데이터 공간을 변환할 함수 (`linear`, `poly`, `rbf`, `sigmoid`). `rbf`(방사 기저 함수)가 가장 많이 쓰입니다.
  - `gamma`: 커널의 계수. `rbf` 커널에서 값이 클수록 결정 경계가 복잡해집니다 (과적합 위험).

#### ③ 다층 퍼셉트론 (Multi-Layer Perceptron, MLP)

- **개념**: 인공 신경망 모델입니다.
- **주요 하이퍼파라미터 (`MLPClassifier`/`Regressor`)**:
  - `hidden_layer_sizes`: 은닉층의 구조 (예: `(100,)`은 100개의 뉴런을 가진 은닉층 1개).
  - `activation`: 활성화 함수 (`relu`, `tanh`, `logistic` 등).
  - `solver`: 가중치 최적화 알고리즘 (`adam`, `sgd`, `lbfgs`). 보통 `adam`이 성능이 좋습니다.
  - `alpha`: L2 규제 계수.
  - `learning_rate_init`: 초기 학습률.

---

## 3. 핵심 개념 및 피처 엔지니어링

### 3.1 피처 스케일링 (Feature Scaling)

데이터의 값의 범위(Scale)가 다르면 모델 학습이 제대로 되지 않는 경우가 있습니다.

- **필수 모델**: 거리 기반(KNN, SVM, K-Means) 및 규제 기반 선형 모델(Ridge, Lasso).
- **불필요 모델**: 트리 기반 모델(Decision Tree, Random Forest 등)은 값의 크기보다 대소 관계가 중요하므로 스케일링이 필요 없습니다.

### 3.2 피처 선택법 (Feature Selection)

모든 변수를 다 쓰는 것이 능사는 아닙니다. 불필요한 변수는 모델의 복잡도를 높이고 과적합을 유발합니다.

- **필터(Filter) 방식**: 통계적 수치(상관계수 등)를 기준으로 상위 변수만 선택.
- **래퍼(Wrapper) 방식**: 변수 조합을 바꿔가며 모델을 계속 학습시켜 최적의 조합을 찾음 (예: RFE).
- **임베디드(Embedded) 방식**: 모델 학습 과정에서 자연스럽게 변수가 선택됨 (예: Lasso, 랜덤 포레스트의 중요도).

### 3.3 과적합(Overfitting)과 편향-분산 트레이드오프

- **High Bias (Underfitting)**: 모델이 너무 단순해서 데이터의 패턴을 다 못 읽은 상태.
- **High Variance (Overfitting)**: 모델이 학습 데이터에만 너무 과하게 맞춰져 새로운 데이터에 대한 예측력이 떨어지는 상태. 규제(Regularization)를 통해 해결합니다.

---

## 4. 비지도 학습 (Unsupervised Learning)

정답(Label) 없이 데이터의 특성 자체를 학습합니다.

### 4.1 K-평균 군집화 (K-Means Clustering)

- **개념**: 데이터를 **K개의 그룹(Cluster)**으로 묶습니다. 중심점과의 거리를 최소화합니다.
- **주요 하이퍼파라미터 (`KMeans`)**:
  - `n_clusters`: 생성할 군집의 개수 K. 가장 중요한 파라미터입니다.
  - `init`: 초기 중심점 설정 방식 (`k-means++` 등을 사용하여 수렴 속도 개선).
  - `max_iter`: 최대 반복 횟수.

### 4.2 주성분 분석 (PCA) - 차원 축소

- **개념**: 고차원 데이터의 **정보(분산)를 최대한 보존**하면서 저차원으로 압축합니다.
- **주요 하이퍼파라미터 (`PCA`)**:
  - `n_components`: 유지할 주성분의 개수. (또는 `0.0`~`1.0` 사이 실수를 입력하여 보존할 분산의 비율 설정 가능).
