# 각 학습과 예측이 쓰이는 상황 및 예시

파일에 있는 **각 단계(1번 ~ 8번)**가 **실제 현업이나 프로젝트에서 어떤 상황에 쓰이는지**, 구체적인 예시를 들어 딱 정리해 드릴게요.

---

### **1. 데이터 로드 및 전체 데이터 학습 (Section 1)**

> `dt_clf.fit(train_data, train_label)` (데이터 분리 없음)

- **언제 쓰나요?**
  - **"내일부터 바로 서비스 시작!" (최종 배포 단계)**
  - 모델의 성능 검증과 튜닝이 **완벽하게 끝난 후**, 실제 운영 서버에 올릴 모델을 만들 때는 아껴뒀던 테스트 데이터까지 몽땅 합쳐서 학습시킵니다. 데이터가 하나라도 더 많아야 실전에서 똑똑하니까요.
- **하면 안 되는 상황**:
  - "이 모델 몇 점이야?" 하고 **성능을 평가할 때**. (이 코드로 평가하면 무조건 100점 나옵니다. 자기기만입니다.)

---

### **2. `train_test_split` (단순 분리) (Section 2, 3)**

> `train_test_split(..., test_size=0.3)`

- **언제 쓰나요?**
  - **"일단 빨리 좀 돌려봐" (빠른 프로토타이핑)**: 아이디어가 떠올라서 모델이 대충 작동하는지 1분 안에 확인하고 싶을 때 씁니다.
  - **"데이터가 너무 많아" (대용량 데이터)**: 데이터가 수십만, 수백만 건이면 한 번만 쪼개도 분포가 충분히 섞입니다. 굳이 시간 오래 걸리는 교차 검증을 안 해도 믿을 만합니다. (딥러닝에서는 거의 이 방식만 씁니다.)
- **상황 예시**:
  - 쇼핑몰 리뷰 데이터 50만 건을 분석할 때. 학습 시간이 오래 걸리니 그냥 8:2로 한 번만 잘라서 씁니다.

---

### **3. K-Fold 교차 검증 (Section 4)**

> `KFold(n_splits=5)`

- **언제 쓰나요?**
  - **"운빨을 믿을 수 없어" (신뢰성 있는 평가)**: 데이터를 한 번만 자르면, 운 좋게 쉬운 문제만 테스트 셋에 걸려서 점수가 뻥튀기될 수 있습니다. 이걸 방지하고 **"모델의 진짜 평균 실력"**을 알고 싶을 때 씁니다.
  - **회귀(Regression) 문제**: 집값 예측, 기온 예측 등 숫자를 맞추는 문제에서 주로 씁니다.
- **상황 예시**:
  - 서울시 아파트 가격 데이터를 가지고 있는데 데이터가 500개밖에 없을 때. 데이터 하나하나가 소중하므로 여러 번 쪼개서 철저하게 검증해야 합니다.

---

### **4. Stratified K-Fold (Section 6)**

> `StratifiedKFold(n_splits=3)`

- **언제 쓰나요?** (중요 ⭐)
  - **분류(Classification) 문제의 표준**: **정답(Target)의 비율을 맞춰서** 쪼개주기 때문에 분류 문제에서는 일반 K-Fold보다 무조건 이걸 씁니다.
  - **"희귀한 데이터를 찾아라" (불균형 데이터)**: 암 환자(1%) vs 정상인(99%) 같은 데이터에서 필수입니다. 일반 K-Fold로 막 자르면, 어떤 폴드에는 암 환자가 한 명도 안 들어갈 수 있습니다.
- **상황 예시**:
  - 은행에서 **사기 거래(Fraud)** 탐지 모델을 만들 때. 사기 거래는 전체의 0.1% 밖에 안 되기 때문에, 이 비율을 유지하며 쪼개주는 Stratified 방식을 써야 정확한 학습이 됩니다.

---

### **5. `cross_val_score` (Section 7)**

> `cross_val_score(dt_clf, ...)`

- **언제 쓰나요?**
  - **"for문 짜기 귀찮아" (실무 최다 빈도)**: 위에서 본 K-Fold for문을 매번 짜면 코드가 길어집니다. 실무에서는 보통 이 함수 한 줄로 검증을 끝냅니다. (분류 문제면 알아서 Stratified 방식이 적용됩니다.)
  - **모델 비교**: "랜덤 포레스트 쓸까? SVM 쓸까?" 고민될 때 빠르게 두 모델의 점수를 뽑아보고 비교할 때 좋습니다.

---

### **6. `GridSearchCV` (Section 8)**

> `GridSearchCV(..., param_grid=parameters)`

- **언제 쓰나요?**
  - **"영혼까지 끌어올려!" (최종 튜닝)**: 모델은 정해졌고, 이제 성능을 95%에서 96%로 올리고 싶을 때 씁니다.
  - 사람이 수동으로 "깊이 3으로 해볼까? 아니면 5?" 하면서 돌리는 건 너무 힘드니, 컴퓨터에게 "3, 4, 5, 6 다 넣어보고 제일 좋은 거 찾아놔"라고 시킬 때 씁니다.
- **상황 예시**:
  - 캐글(Kaggle) 대회 마감 하루 전, 0.001점이라도 더 올려서 등수를 뒤집어야 할 때 파라미터 수십 개를 던져놓고 자고 일어납니다.

---

**요약하자면:**

1.  평소엔 **`train_test_split`**으로 가볍게 시작.
2.  정확한 성능 리포트가 필요하면 **`cross_val_score`**.
3.  성능 욕심이 나면 **`GridSearchCV`**.
4.  최종 납품할 땐 **전체 데이터 학습**.
